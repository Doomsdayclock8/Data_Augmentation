{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#COMPARISON IN THE LATENT SPACE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import random\n",
        "\n",
        "# Autoencoder definition\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, latent_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded\n",
        "\n",
        "# Diffusion model definition\n",
        "class DiffusionModel(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(DiffusionModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/mammography_dataset.csv', header=None)\n",
        "\n",
        "# Separate features and target\n",
        "y = data.iloc[:, -1]\n",
        "X = data.iloc[:, :-1]\n",
        "\n",
        "# Preprocessing\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
        "\n",
        "# Autoencoder parameters\n",
        "input_dim = X_tensor.shape[1]\n",
        "latent_dim = 3\n",
        "model = Autoencoder(input_dim, latent_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training the autoencoder\n",
        "num_epochs = 50\n",
        "batch_size = 32\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i in range(0, X_tensor.size(0), batch_size):\n",
        "        batch = X_tensor[i:i+batch_size]\n",
        "        optimizer.zero_grad()\n",
        "        encoded, decoded = model(batch)\n",
        "        loss = criterion(decoded, batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Extract latent space representation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    latent_space = model.encoder(X_tensor).numpy()\n",
        "\n",
        "# Save latent space to CSV\n",
        "latent_space_df = pd.DataFrame(latent_space)\n",
        "latent_space_df['target'] = y.values\n",
        "latent_space_df.to_csv('/content/latent_space.csv', index=False)\n",
        "\n",
        "# Split into train and test in the latent space\n",
        "train_data, test_data = train_test_split(latent_space_df, test_size=0.2, stratify=latent_space_df['target'], random_state=42)\n",
        "\n",
        "# Separate features and target for train and test\n",
        "X_train, y_train = train_data.iloc[:, :-1], train_data['target']\n",
        "X_test, y_test = test_data.iloc[:, :-1], test_data['target']\n",
        "\n",
        "# Augment minority class (class 1) in latent space using diffusion model\n",
        "minority_data = X_train[y_train == 1].values\n",
        "num_augment = len(minority_data)  # 100% augmentation\n",
        "\n",
        "# Initialize diffusion model\n",
        "diffusion_model = DiffusionModel(latent_dim)\n",
        "diffusion_optimizer = Adam(diffusion_model.parameters(), lr=0.001)\n",
        "\n",
        "# Train diffusion model\n",
        "num_diffusion_epochs = 100\n",
        "minority_tensor = torch.tensor(minority_data, dtype=torch.float32)\n",
        "for epoch in range(num_diffusion_epochs):\n",
        "    diffusion_optimizer.zero_grad()\n",
        "    noise = torch.randn_like(minority_tensor) * 0.1\n",
        "    noisy_data = minority_tensor + noise\n",
        "    generated_data = diffusion_model(noisy_data)\n",
        "    loss = nn.MSELoss()(generated_data, minority_tensor)\n",
        "    loss.backward()\n",
        "    diffusion_optimizer.step()\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Diffusion Epoch [{epoch+1}/{num_diffusion_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Generate augmented data\n",
        "with torch.no_grad():\n",
        "    augmented_minority = diffusion_model(minority_tensor + torch.randn_like(minority_tensor) * 0.1).numpy()\n",
        "\n",
        "# Combine augmented data with original latent space training data\n",
        "latent_train_augmented = np.vstack([X_train, augmented_minority])\n",
        "y_train_augmented = np.hstack([y_train, np.ones(num_augment)])\n",
        "\n",
        "# Train classifiers and compare recall\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Without augmentation\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_original = clf.predict(X_test)\n",
        "print(\"Performance without augmentation:\")\n",
        "print(classification_report(y_test, y_pred_original))\n",
        "\n",
        "# With augmentation\n",
        "clf.fit(latent_train_augmented, y_train_augmented)\n",
        "y_pred_augmented = clf.predict(X_test)\n",
        "print(\"Performance with augmentation:\")\n",
        "print(classification_report(y_test, y_pred_augmented))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ0RrrPwPLQ9",
        "outputId": "0d9d6e74-f4f5-4522-f01d-b9eb8f20a09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Loss: 0.0003\n",
            "Epoch [20/50], Loss: 0.0003\n",
            "Epoch [30/50], Loss: 0.0003\n",
            "Epoch [40/50], Loss: 0.0003\n",
            "Epoch [50/50], Loss: 0.0003\n",
            "Diffusion Epoch [10/100], Loss: 0.0334\n",
            "Diffusion Epoch [20/100], Loss: 0.0113\n",
            "Diffusion Epoch [30/100], Loss: 0.0089\n",
            "Diffusion Epoch [40/100], Loss: 0.0073\n",
            "Diffusion Epoch [50/100], Loss: 0.0067\n",
            "Diffusion Epoch [60/100], Loss: 0.0064\n",
            "Diffusion Epoch [70/100], Loss: 0.0063\n",
            "Diffusion Epoch [80/100], Loss: 0.0062\n",
            "Diffusion Epoch [90/100], Loss: 0.0061\n",
            "Diffusion Epoch [100/100], Loss: 0.0051\n",
            "Performance without augmentation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99      2185\n",
            "           1       0.81      0.40      0.54        52\n",
            "\n",
            "    accuracy                           0.98      2237\n",
            "   macro avg       0.90      0.70      0.77      2237\n",
            "weighted avg       0.98      0.98      0.98      2237\n",
            "\n",
            "Performance with augmentation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      2185\n",
            "           1       0.71      0.62      0.66        52\n",
            "\n",
            "    accuracy                           0.99      2237\n",
            "   macro avg       0.85      0.80      0.83      2237\n",
            "weighted avg       0.98      0.99      0.98      2237\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#COMPARISON IN THE ORIGINAL SPACE AFTER DECODING\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import random\n",
        "\n",
        "# Autoencoder definition\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, latent_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded\n",
        "\n",
        "# Diffusion model definition\n",
        "class DiffusionModel(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(DiffusionModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/mammography_dataset.csv', header=None)\n",
        "\n",
        "# Separate features and target\n",
        "y = data.iloc[:, -1]\n",
        "X = data.iloc[:, :-1]\n",
        "\n",
        "# Preprocessing\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split into train and test before autoencoding\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "# Autoencoder parameters\n",
        "input_dim = X_train_tensor.shape[1]\n",
        "latent_dim = 3\n",
        "model = Autoencoder(input_dim, latent_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training the autoencoder\n",
        "num_epochs = 50\n",
        "batch_size = 32\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i in range(0, X_train_tensor.size(0), batch_size):\n",
        "        batch = X_train_tensor[i:i+batch_size]\n",
        "        optimizer.zero_grad()\n",
        "        encoded, decoded = model(batch)\n",
        "        loss = criterion(decoded, batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Extract latent space representation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    latent_train = model.encoder(X_train_tensor).numpy()\n",
        "    latent_test = model.encoder(X_test_tensor).numpy()\n",
        "\n",
        "# Augment minority class (class 1) in latent space using diffusion model\n",
        "minority_data = latent_train[y_train == 1]\n",
        "num_augment = len(minority_data)  # 100% augmentation\n",
        "\n",
        "# Initialize diffusion model\n",
        "diffusion_model = DiffusionModel(latent_dim)\n",
        "diffusion_optimizer = Adam(diffusion_model.parameters(), lr=0.001)\n",
        "\n",
        "# Train diffusion model\n",
        "num_diffusion_epochs = 100\n",
        "minority_tensor = torch.tensor(minority_data, dtype=torch.float32)\n",
        "for epoch in range(num_diffusion_epochs):\n",
        "    diffusion_optimizer.zero_grad()\n",
        "    noise = torch.randn_like(minority_tensor) * 0.1\n",
        "    noisy_data = minority_tensor + noise\n",
        "    generated_data = diffusion_model(noisy_data)\n",
        "    loss = nn.MSELoss()(generated_data, minority_tensor)\n",
        "    loss.backward()\n",
        "    diffusion_optimizer.step()\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Diffusion Epoch [{epoch+1}/{num_diffusion_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Generate augmented data\n",
        "with torch.no_grad():\n",
        "    augmented_minority = diffusion_model(minority_tensor + torch.randn_like(minority_tensor) * 0.1).numpy()\n",
        "\n",
        "# Combine augmented data with original latent space training data\n",
        "latent_train_augmented = np.vstack([latent_train, augmented_minority])\n",
        "y_train_augmented = np.hstack([y_train, np.ones(num_augment)])\n",
        "\n",
        "# Decode augmented data back to original space\n",
        "with torch.no_grad():\n",
        "    decoded_augmented = model.decoder(torch.tensor(latent_train_augmented, dtype=torch.float32)).numpy()\n",
        "\n",
        "# Combine decoded augmented data with original training data in original space\n",
        "X_train_augmented_original_space = np.vstack([X_train, decoded_augmented[len(latent_train):]])\n",
        "y_train_augmented_original_space = np.hstack([y_train, np.ones(num_augment)])\n",
        "\n",
        "# Train classifiers and compare recall\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Without augmentation\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_original = clf.predict(X_test)\n",
        "print(\"Performance without augmentation:\")\n",
        "print(classification_report(y_test, y_pred_original))\n",
        "\n",
        "# With augmentation in original space\n",
        "clf.fit(X_train_augmented_original_space, y_train_augmented_original_space)\n",
        "y_pred_augmented = clf.predict(X_test)\n",
        "print(\"Performance with augmentation (decoded back to original space):\")\n",
        "print(classification_report(y_test, y_pred_augmented))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOo5zNksR2Dp",
        "outputId": "47492bbe-ab3c-47cc-c09d-bc92f6d66cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Loss: 0.0001\n",
            "Epoch [20/50], Loss: 0.0003\n",
            "Epoch [30/50], Loss: 0.0001\n",
            "Epoch [40/50], Loss: 0.0001\n",
            "Epoch [50/50], Loss: 0.0001\n",
            "Diffusion Epoch [10/100], Loss: 0.0257\n",
            "Diffusion Epoch [20/100], Loss: 0.0094\n",
            "Diffusion Epoch [30/100], Loss: 0.0080\n",
            "Diffusion Epoch [40/100], Loss: 0.0064\n",
            "Diffusion Epoch [50/100], Loss: 0.0057\n",
            "Diffusion Epoch [60/100], Loss: 0.0063\n",
            "Diffusion Epoch [70/100], Loss: 0.0056\n",
            "Diffusion Epoch [80/100], Loss: 0.0058\n",
            "Diffusion Epoch [90/100], Loss: 0.0056\n",
            "Diffusion Epoch [100/100], Loss: 0.0058\n",
            "Performance without augmentation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99      2185\n",
            "           1       0.86      0.48      0.62        52\n",
            "\n",
            "    accuracy                           0.99      2237\n",
            "   macro avg       0.92      0.74      0.81      2237\n",
            "weighted avg       0.98      0.99      0.98      2237\n",
            "\n",
            "Performance with augmentation (decoded back to original space):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99      2185\n",
            "           1       0.83      0.56      0.67        52\n",
            "\n",
            "    accuracy                           0.99      2237\n",
            "   macro avg       0.91      0.78      0.83      2237\n",
            "weighted avg       0.99      0.99      0.99      2237\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import random\n",
        "\n",
        "# Autoencoder definition\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, latent_dim)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/diabetes.csv', header=None)\n",
        "\n",
        "# Separate features and target\n",
        "y = data.iloc[:, -1]\n",
        "X = data.iloc[:, :-1]\n",
        "\n",
        "# Preprocessing\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split into train and test before autoencoding\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "\n",
        "# Autoencoder parameters\n",
        "input_dim = X_train_tensor.shape[1]\n",
        "latent_dim = 3\n",
        "model = Autoencoder(input_dim, latent_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training the autoencoder\n",
        "num_epochs = 50\n",
        "batch_size = 32\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i in range(0, X_train_tensor.size(0), batch_size):\n",
        "        batch = X_train_tensor[i:i+batch_size]\n",
        "        optimizer.zero_grad()\n",
        "        encoded, decoded = model(batch)\n",
        "        loss = criterion(decoded, batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Extract latent space representation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    latent_train = model.encoder(X_train_tensor).numpy()\n",
        "    latent_test = model.encoder(X_test_tensor).numpy()\n",
        "\n",
        "# Augment minority class (class 1) in latent space\n",
        "minority_data = latent_train[y_train == 1]\n",
        "num_augment = len(minority_data)  # 100% augmentation\n",
        "noise = np.random.normal(0, 0.1, size=minority_data.shape)\n",
        "augmented_minority = minority_data + noise\n",
        "\n",
        "# Combine augmented data with original latent space training data\n",
        "latent_train_augmented = np.vstack([latent_train, augmented_minority])\n",
        "y_train_augmented = np.hstack([y_train, np.ones(num_augment)])\n",
        "\n",
        "# Decode augmented data back to original space\n",
        "with torch.no_grad():\n",
        "    decoded_augmented = model.decoder(torch.tensor(latent_train_augmented, dtype=torch.float32)).numpy()\n",
        "\n",
        "# Combine decoded augmented data with original training data in original space\n",
        "X_train_augmented_original_space = np.vstack([X_train, decoded_augmented[len(latent_train):]])\n",
        "y_train_augmented_original_space = np.hstack([y_train, np.ones(num_augment)])\n",
        "\n",
        "# Train classifiers and compare recall\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Without augmentation\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_original = clf.predict(X_test)\n",
        "print(\"Performance without augmentation:\")\n",
        "print(classification_report(y_test, y_pred_original))\n",
        "\n",
        "# With augmentation in original space\n",
        "clf.fit(X_train_augmented_original_space, y_train_augmented_original_space)\n",
        "y_pred_augmented = clf.predict(X_test)\n",
        "print(\"Performance with augmentation (decoded back to original space):\")\n",
        "print(classification_report(y_test, y_pred_augmented))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kobyDwD3QzI3",
        "outputId": "ce6ebbc9-d159-4802-c5a6-69a3380136d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Loss: 0.0058\n",
            "Epoch [20/50], Loss: 0.0061\n",
            "Epoch [30/50], Loss: 0.0047\n",
            "Epoch [40/50], Loss: 0.0045\n",
            "Epoch [50/50], Loss: 0.0046\n",
            "Performance without augmentation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.85      0.82       100\n",
            "           1       0.67      0.57      0.62        54\n",
            "\n",
            "    accuracy                           0.75       154\n",
            "   macro avg       0.73      0.71      0.72       154\n",
            "weighted avg       0.75      0.75      0.75       154\n",
            "\n",
            "Performance with augmentation (decoded back to original space):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.82      0.81       100\n",
            "           1       0.65      0.63      0.64        54\n",
            "\n",
            "    accuracy                           0.75       154\n",
            "   macro avg       0.73      0.72      0.73       154\n",
            "weighted avg       0.75      0.75      0.75       154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "4x8YO65ww-AO",
        "outputId": "8d93187b-160f-4c04-9094-91cf38fb422d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/50], Loss: 0.0210\n",
            "Epoch [20/50], Loss: 0.0164\n",
            "Epoch [30/50], Loss: 0.0159\n",
            "Epoch [40/50], Loss: 0.0158\n",
            "Epoch [50/50], Loss: 0.0157\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latent space dataset saved as 'latent_space_diabetes_pytorch.csv'.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "data = load_diabetes()\n",
        "X = data.data\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
        "\n",
        "# Define the autoencoder structure\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, encoding_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, encoding_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(encoding_dim, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded\n",
        "\n",
        "# Parameters\n",
        "input_dim = X_tensor.shape[1]\n",
        "encoding_dim = 2\n",
        "\n",
        "# Model, loss, optimizer\n",
        "model = Autoencoder(input_dim=input_dim, encoding_dim=encoding_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training the autoencoder\n",
        "num_epochs = 50\n",
        "batch_size = 16\n",
        "losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i in range(0, X_tensor.size(0), batch_size):\n",
        "        batch = X_tensor[i:i+batch_size]\n",
        "        optimizer.zero_grad()\n",
        "        _, decoded = model(batch)\n",
        "        loss = criterion(decoded, batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    losses.append(loss.item())\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Plot training loss\n",
        "plt.plot(losses, label='Training Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Extract latent space representation\n",
        "with torch.no_grad():\n",
        "    latent_space, _ = model(X_tensor)\n",
        "\n",
        "# Convert latent space to DataFrame\n",
        "latent_space_np = latent_space.numpy()\n",
        "latent_space_df = pd.DataFrame(latent_space_np, columns=[f'Latent_{i+1}' for i in range(encoding_dim)])\n",
        "\n",
        "# Save latent space dataset\n",
        "latent_space_df.to_csv('latent_space_diabetes_pytorch.csv', index=False)\n",
        "print(\"Latent space dataset saved as 'latent_space_diabetes_pytorch.csv'.\")\n"
      ]
    }
  ]
}