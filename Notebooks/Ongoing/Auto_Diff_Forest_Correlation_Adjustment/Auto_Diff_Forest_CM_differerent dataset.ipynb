{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Define the path to your folder\n",
    "folder_path = f'..\\\\..\\\\..\\\\Models\\\\AutoDiffusion' \n",
    "\n",
    "# Add the folder to sys.path\n",
    "sys.path.append(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import process_edited as pce\n",
    "import process_GQ as pce\n",
    "import autoencoder as ae\n",
    "import diffusion as diff\n",
    "import TabDDPMdiff as TabDiff\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to adjust the correlations of the generated data\n",
    "def adjust_correlation(X, target_corr_matrix):\n",
    "    L = np.linalg.cholesky(target_corr_matrix)\n",
    "    X_centered = X - np.mean(X, axis=0)\n",
    "    X_transformed = np.dot(X_centered, L.T)\n",
    "    return X_transformed + np.mean(X, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Metrics for AutoDiff Autoencoder & ForestDIffusion for HTRU dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ee7ed488274ed6a65e25d3d39f66e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before augmentation: {0: 16259, 1: 1639}\n",
      "Class distribution after augmentation: {0.0: 16259, 1.0: 1739}\n",
      "Precision score (original data): 0.9376\n",
      "Precision score (generated data): 0.9727\n",
      "Recall score (original data): 0.8354\n",
      "Recall score (generated data): 0.8807\n",
      "F1 score (original data): 0.8836\n",
      "F1 score (generated data): 0.9244\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      4884\n",
      "           1       0.94      0.84      0.88       486\n",
      "\n",
      "    accuracy                           0.98      5370\n",
      "   macro avg       0.96      0.91      0.94      5370\n",
      "weighted avg       0.98      0.98      0.98      5370\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4884\n",
      "           1       0.97      0.88      0.92       486\n",
      "\n",
      "    accuracy                           0.99      5370\n",
      "   macro avg       0.98      0.94      0.96      5370\n",
      "weighted avg       0.99      0.99      0.99      5370\n",
      "\n",
      "Number of fake samples generated: 100\n",
      "Result Metrics for AutoDiff Autoencoder & ForestDIffusion for diabetes dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840eddf524f5478e84e9ea4b34148e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before augmentation: {0: 500, 1: 268}\n",
      "Class distribution after augmentation: {0.0: 500, 1.0: 368}\n",
      "Precision score (original data): 0.6386\n",
      "Precision score (generated data): 0.7647\n",
      "Recall score (original data): 0.6625\n",
      "Recall score (generated data): 0.8125\n",
      "F1 score (original data): 0.6503\n",
      "F1 score (generated data): 0.7879\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81       151\n",
      "           1       0.64      0.66      0.65        80\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.73      0.73      0.73       231\n",
      "weighted avg       0.76      0.75      0.75       231\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88       151\n",
      "           1       0.76      0.81      0.79        80\n",
      "\n",
      "    accuracy                           0.85       231\n",
      "   macro avg       0.83      0.84      0.84       231\n",
      "weighted avg       0.85      0.85      0.85       231\n",
      "\n",
      "Number of fake samples generated: 100\n",
      "Result Metrics for AutoDiff Autoencoder & ForestDIffusion for mammography dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5162866e0af4402096751e5083afc3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before augmentation: {-1: 10923, 1: 260}\n",
      "Class distribution after augmentation: {-1.0: 10923, 1.0: 360}\n",
      "Precision score (original data): 0.9167\n",
      "Precision score (generated data): 0.9310\n",
      "Recall score (original data): 0.5946\n",
      "Recall score (generated data): 0.7297\n",
      "F1 score (original data): 0.7213\n",
      "F1 score (generated data): 0.8182\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      0.99      3281\n",
      "           1       0.92      0.59      0.72        74\n",
      "\n",
      "    accuracy                           0.99      3355\n",
      "   macro avg       0.95      0.80      0.86      3355\n",
      "weighted avg       0.99      0.99      0.99      3355\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      1.00      3281\n",
      "           1       0.93      0.73      0.82        74\n",
      "\n",
      "    accuracy                           0.99      3355\n",
      "   macro avg       0.96      0.86      0.91      3355\n",
      "weighted avg       0.99      0.99      0.99      3355\n",
      "\n",
      "Number of fake samples generated: 100\n",
      "Result Metrics for AutoDiff Autoencoder & ForestDIffusion for creditcard_sampled dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3912ba87f2b45d5bde48f69e9950ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before augmentation: {0: 4000, 1: 50}\n",
      "Class distribution after augmentation: {0.0: 4000, 1.0: 100}\n",
      "Precision score (original data): 0.8667\n",
      "Precision score (generated data): 0.8750\n",
      "Recall score (original data): 0.7647\n",
      "Recall score (generated data): 0.8235\n",
      "F1 score (original data): 0.8125\n",
      "F1 score (generated data): 0.8485\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1198\n",
      "           1       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           1.00      1215\n",
      "   macro avg       0.93      0.88      0.90      1215\n",
      "weighted avg       0.99      1.00      0.99      1215\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1198\n",
      "           1       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           1.00      1215\n",
      "   macro avg       0.94      0.91      0.92      1215\n",
      "weighted avg       1.00      1.00      1.00      1215\n",
      "\n",
      "Number of fake samples generated: 50\n",
      "Result Metrics for AutoDiff Autoencoder & ForestDIffusion for yeast_ml8_dataset dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c816b5044d4889bd29c6ab4f057e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before augmentation: {-1: 2239, 1: 178}\n",
      "Class distribution after augmentation: {-1.0: 2239, 1.0: 278}\n",
      "Precision score (original data): 0.0000\n",
      "Precision score (generated data): 1.0000\n",
      "Recall score (original data): 0.0000\n",
      "Recall score (generated data): 0.5510\n",
      "F1 score (original data): 0.0000\n",
      "F1 score (generated data): 0.7105\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      1.00      0.97       677\n",
      "           1       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.93       726\n",
      "   macro avg       0.47      0.50      0.48       726\n",
      "weighted avg       0.87      0.93      0.90       726\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      1.00      0.98       677\n",
      "           1       1.00      0.55      0.71        49\n",
      "\n",
      "    accuracy                           0.97       726\n",
      "   macro avg       0.98      0.78      0.85       726\n",
      "weighted avg       0.97      0.97      0.97       726\n",
      "\n",
      "Number of fake samples generated: 100\n",
      "Result Metrics for AutoDiff Autoencoder & ForestDIffusion for oil dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tawfi\\Thesis\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tawfi\\Thesis\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tawfi\\Thesis\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tawfi\\Thesis\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ca2c06207e43ad8b635f850fcc4dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "LinAlgError",
     "evalue": "Matrix is not positive definite",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 50\u001b[0m\n\u001b[0;32m     46\u001b[0m minority_fake \u001b[38;5;241m=\u001b[39m forest_model\u001b[38;5;241m.\u001b[39mgenerate(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(real_minortiy)) \u001b[38;5;66;03m# Adjust the batch size to create a balanced dataset\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Step 6: Adjust the synthetic data to match the original data's correlation matrix\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m X_minority_fake_adjusted \u001b[38;5;241m=\u001b[39m \u001b[43madjust_correlation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminority_fake\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrelation_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m sample\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(X_minority_fake_adjusted, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     54\u001b[0m sample\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m, in \u001b[0;36madjust_correlation\u001b[1;34m(X, target_corr_matrix)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madjust_correlation\u001b[39m(X, target_corr_matrix):\n\u001b[1;32m----> 3\u001b[0m     L \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_corr_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     X_centered \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      5\u001b[0m     X_transformed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X_centered, L\u001b[38;5;241m.\u001b[39mT)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mcholesky\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\tawfi\\Thesis\\env\\Lib\\site-packages\\numpy\\linalg\\linalg.py:756\u001b[0m, in \u001b[0;36mcholesky\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    754\u001b[0m t, result_t \u001b[38;5;241m=\u001b[39m _commonType(a)\n\u001b[0;32m    755\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 756\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(r\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\tawfi\\Thesis\\env\\Lib\\site-packages\\numpy\\linalg\\linalg.py:92\u001b[0m, in \u001b[0;36m_raise_linalgerror_nonposdef\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_nonposdef\u001b[39m(err, flag):\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatrix is not positive definite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Matrix is not positive definite"
     ]
    }
   ],
   "source": [
    "strings_set = {'diabetes','oil','yeast_ml8_dataset','creditcard_sampled','HTRU','mammography'}\n",
    "Model = 'AutoDiff'\n",
    "# dataset = 'diabetes'\n",
    "metrics_list = []\n",
    "for dataset in strings_set:\n",
    "    print(f\"Result Metrics for AutoDiff Autoencoder & ForestDIffusion for {dataset} dataset\")\n",
    "    file_path = f'..\\\\..\\\\..\\\\Datasets\\\\Original Data\\\\{dataset}.csv'\n",
    "    # Read dataframe\n",
    "    # print(file_path)\n",
    "    real_df = pd.read_csv(file_path)\n",
    "    #real_df = real_df.drop('url', axis=1)\n",
    "    # # Step 2: Inspect the data and check for class imbalance\n",
    "    # # Assuming the last column is the label, and the rest are features\n",
    "    X = real_df.iloc[:, :-1].values  # Features\n",
    "    y = real_df.iloc[:, -1].values  # Labels (binary classification)\n",
    "    #  # Separate the minority class\n",
    "    # Find the minority class\n",
    "\n",
    "    real_minortiy = real_df[y == 1]\n",
    "\n",
    "    threshold = 0.01 # Threshold for mixed-type variables\n",
    "    parser = pce.DataFrameParser().fit(real_minortiy, threshold)\n",
    "    ################################################################################################################\n",
    "    # Auto-encoder hyper-parameters\n",
    "    device = 'cuda' #@param {'type':'string'}\n",
    "    n_epochs = 2000 #@param {'type':'integer'}\n",
    "    eps = 1e-5 #@param {type:\"number\"}\n",
    "    weight_decay = 1e-6 #@param {'type':'number'}\n",
    "    maximum_learning_rate = 1e-2 #@param {'type':'number'}\n",
    "    lr = 2e-4 #@param {'type':'number'}\n",
    "    hidden_size = 250\n",
    "    num_layers = 3\n",
    "    batch_size = real_minortiy.shape[0] # Full batch\n",
    "\n",
    "    ds = ae.train_autoencoder(real_minortiy, hidden_size, num_layers, lr, weight_decay, n_epochs, batch_size, threshold)\n",
    "    latent_features = ds[1].detach()\n",
    "\n",
    "    from ForestDiffusion import ForestDiffusionModel\n",
    "\n",
    "\n",
    "    # Convert to NumPy array\n",
    "    array = latent_features.detach().cpu().numpy()\n",
    "\n",
    "    correlation_matrix = pd.DataFrame(array).corr()\n",
    "    forest_model = ForestDiffusionModel(array, label_y=None, n_t=50, duplicate_K=100, bin_indexes=[], cat_indexes=[], int_indexes=[], diffusion_type='flow', n_jobs=-1)\n",
    "    minority_fake = forest_model.generate(batch_size=len(real_minortiy)) # Adjust the batch size to create a balanced dataset\n",
    "\n",
    "\n",
    "    # Step 6: Adjust the synthetic data to match the original data's correlation matrix\n",
    "    X_minority_fake_adjusted = adjust_correlation(minority_fake, correlation_matrix)\n",
    "\n",
    "\n",
    "    sample=torch.tensor(X_minority_fake_adjusted, dtype=torch.float32)\n",
    "    sample.shape\n",
    "    gen_output = ds[0](sample, ds[2], ds[3])\n",
    "    gen_df = pce.convert_to_table(real_minortiy, gen_output, threshold)\n",
    "\n",
    "    output_directory =  f'..\\\\..\\\\..\\\\Datasets\\\\Synthetic Data\\\\'\n",
    "    filename = f'{Model}+Forest_{dataset}_Synthetic.csv'\n",
    "    output_file = os.path.join(output_directory, filename)\n",
    "    gen_df.to_csv(output_file, index=False) \n",
    "\n",
    "\n",
    "    # Select a random sample of the generated data\n",
    "    selected_samples = gen_df.sample(n=min(100,gen_df.shape[0]), random_state=42)  # For reproducibility\n",
    "    # Syn _df will be the dataset after augmentation\n",
    "    syn_df = pd.concat([real_df, selected_samples], ignore_index=True)\n",
    "\n",
    "\n",
    "    augmented_output_directory =  f'..\\\\..\\\\..\\\\Datasets\\\\Augmented Data\\\\'\n",
    "    filename = f'{Model}+Forest_{dataset}_Augmented.csv'\n",
    "    augmented_output_file = os.path.join(augmented_output_directory, filename)\n",
    "    syn_df.to_csv(augmented_output_file, index=False) \n",
    "\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from ForestDiffusion import ForestDiffusionModel\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "    # real_df = pd.read_csv(filename)\n",
    "    # syn_filename = f'{string}/{Model}_{string}_Augmented.csv'\n",
    "\n",
    "    # augmented_df = pd.read_csv(syn_filename)\n",
    "    augmented_df=syn_df\n",
    "\n",
    "    X = real_df.iloc[:, :-1].values  # Features\n",
    "    y = real_df.iloc[:, -1].values \n",
    "    # Check and print the original class distribution\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    class_dist_before = dict(zip(unique, counts))\n",
    "    print(f\"Class distribution before augmentation: {class_dist_before}\")# Labels (binary classification)\n",
    "\n",
    "    X_balanced = augmented_df.iloc[:, :-1].values  # Features\n",
    "    y_balanced = augmented_df.iloc[:, -1].values  # Labels (binary classification)\n",
    "\n",
    "    # Check and print the Augmented class distribution\n",
    "    unique, counts = np.unique(y_balanced, return_counts=True)\n",
    "    class_dist_after = dict(zip(unique, counts))\n",
    "    print(f\"Class distribution after augmentation: {class_dist_after}\")\n",
    "\n",
    "    # Step 6: Split the dataset into training and test sets (original and balanced)\n",
    "    X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_balanced, y_balanced, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Step 7: Train a simple classifier on both original and generated datasets\n",
    "    clf_orig = RandomForestClassifier(random_state=42)\n",
    "    clf_orig.fit(X_train_orig, y_train_orig)\n",
    "\n",
    "    clf_bal = RandomForestClassifier(random_state=42)\n",
    "    clf_bal.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "    # Step 8: Predict and calculate recall and F1 scores\n",
    "    y_pred_orig = clf_orig.predict(X_test_orig)\n",
    "    y_pred_bal = clf_bal.predict(X_test_orig)\n",
    "\n",
    "    prec_orig = precision_score(y_test_orig, y_pred_orig)\n",
    "    prec_bal = precision_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "    recall_orig = recall_score(y_test_orig, y_pred_orig)\n",
    "    recalls_bal = recall_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "    f1_orig = f1_score(y_test_orig, y_pred_orig)\n",
    "    f1_bal = f1_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "    # Step 9: Print and store the performance metrics\n",
    "    # Store metrics in a dictionary\n",
    "    metrics = {\n",
    "    \"Dataset\": dataset,\n",
    "    \"Precision_Original\": prec_orig,\n",
    "    \"Precision_Generated\": prec_bal,\n",
    "    \"Recall_Original\": recall_orig,\n",
    "    \"Recall_Generated\": recalls_bal,\n",
    "    \"F1_Original\": f1_orig,   \n",
    "    \"F1_Generated\": f1_bal,\n",
    "    \"Num_Fake_Samples\": len(augmented_df) - len(real_df),\n",
    "    \"Synthetic/Original_Ratio\":100*(len(augmented_df) - len(real_df))/len(real_minortiy)\n",
    "    }\n",
    "\n",
    "    # Append the dictionary to the list\n",
    "    metrics_list.append(metrics)\n",
    "\n",
    "    print(f\"Precision score (original data): {prec_orig:.4f}\")\n",
    "    print(f\"Precision score (generated data): {prec_bal:.4f}\")\n",
    "    print(f\"Recall score (original data): {recall_orig:.4f}\")\n",
    "    print(f\"Recall score (generated data): {recalls_bal:.4f}\")\n",
    "    print(f\"F1 score (original data): {f1_orig:.4f}\")\n",
    "    print(f\"F1 score (generated data): {f1_bal:.4f}\")\n",
    "    print(\"Classification Report (original data):\\n\", classification_report(y_test_orig, y_pred_orig))\n",
    "    print(\"Classification Report (generated data):\\n\", classification_report(y_test_orig, y_pred_bal))\n",
    "\n",
    "\n",
    "    print(f\"Number of fake samples generated: {len(augmented_df)-len(real_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Precision_Original</th>\n",
       "      <th>Precision_Generated</th>\n",
       "      <th>Recall_Original</th>\n",
       "      <th>Recall_Generated</th>\n",
       "      <th>F1_Original</th>\n",
       "      <th>F1_Generated</th>\n",
       "      <th>Num_Fake_Samples</th>\n",
       "      <th>Synthetic/Original_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HTRU</td>\n",
       "      <td>0.937644</td>\n",
       "      <td>0.972727</td>\n",
       "      <td>0.835391</td>\n",
       "      <td>0.880658</td>\n",
       "      <td>0.883569</td>\n",
       "      <td>0.924406</td>\n",
       "      <td>100</td>\n",
       "      <td>6.101281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.650307</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>100</td>\n",
       "      <td>37.313433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mammography</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>100</td>\n",
       "      <td>38.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>creditcard_sampled</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>50</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeast_ml8_dataset</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.551020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>100</td>\n",
       "      <td>56.179775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dataset  Precision_Original  Precision_Generated  \\\n",
       "0                HTRU            0.937644             0.972727   \n",
       "1            diabetes            0.638554             0.764706   \n",
       "2         mammography            0.916667             0.931034   \n",
       "3  creditcard_sampled            0.866667             0.875000   \n",
       "4   yeast_ml8_dataset            0.000000             1.000000   \n",
       "\n",
       "   Recall_Original  Recall_Generated  F1_Original  F1_Generated  \\\n",
       "0         0.835391          0.880658     0.883569      0.924406   \n",
       "1         0.662500          0.812500     0.650307      0.787879   \n",
       "2         0.594595          0.729730     0.721311      0.818182   \n",
       "3         0.764706          0.823529     0.812500      0.848485   \n",
       "4         0.000000          0.551020     0.000000      0.710526   \n",
       "\n",
       "   Num_Fake_Samples  Synthetic/Original_Ratio  \n",
       "0               100                  6.101281  \n",
       "1               100                 37.313433  \n",
       "2               100                 38.461538  \n",
       "3                50                100.000000  \n",
       "4               100                 56.179775  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "metrics_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
