{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Define the path to your folder\n",
    "folder_path = f'..\\\\..\\\\..\\\\Models\\\\AutoDiffusion' \n",
    "\n",
    "# Add the folder to sys.path\n",
    "sys.path.append(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#import process_edited as pce\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mprocess_GQ\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpce\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mautoencoder\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mae\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdiffusion\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdiff\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tawfique\\Thesis\\Data_Augmentation\\Notebooks\\Ongoing\\AutoDiff+Forest\\..\\..\\..\\Models\\AutoDiffusion\\process_GQ.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStandardScaler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabelEncoder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFreqLabelEncoder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataFrameParser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSingleDataset\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mStandardScaler\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Tawfique\\Python\\Environments\\ThesisEnv\\lib\\site-packages\\sklearn\\__init__.py:82\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _distributor_init  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __check_build  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     85\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    129\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\Tawfique\\Python\\Environments\\ThesisEnv\\lib\\site-packages\\sklearn\\base.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_set_output\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _SetOutputMixin\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tags\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     _DEFAULT_TAGS,\n\u001b[0;32m     21\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Tawfique\\Python\\Environments\\ThesisEnv\\lib\\site-packages\\sklearn\\utils\\__init__.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmurmurhash\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m murmurhash3_32\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib\n",
      "File \u001b[1;32msklearn\\utils\\murmurhash.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.utils.murmurhash\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import process_edited as pce\n",
    "import process_GQ as pce\n",
    "import autoencoder as ae\n",
    "import diffusion as diff\n",
    "import TabDDPMdiff as TabDiff\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Metrics for AutoDiff Autoencoder & ForestDIffusion for yeast_ml8_dataset dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f894aee6c5f47b9a23dc82c83ca3a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before augmentation: {-1: 2239, 1: 178}\n",
      "Class distribution after augmentation: {-1.0: 2239, 1.0: 278}\n",
      "Precision score (original data): 0.0000\n",
      "Precision score (generated data): 1.0000\n",
      "Recall score (original data): 0.0000\n",
      "Recall score (generated data): 0.5510\n",
      "F1 score (original data): 0.0000\n",
      "F1 score (generated data): 0.7105\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      1.00      0.97       677\n",
      "           1       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.93       726\n",
      "   macro avg       0.47      0.50      0.48       726\n",
      "weighted avg       0.87      0.93      0.90       726\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      1.00      0.98       677\n",
      "           1       1.00      0.55      0.71        49\n",
      "\n",
      "    accuracy                           0.97       726\n",
      "   macro avg       0.98      0.78      0.85       726\n",
      "weighted avg       0.97      0.97      0.97       726\n",
      "\n",
      "Number of fake samples generated: 100\n",
      "Result Metrics for AutoDiff Autoencoder & ForestDIffusion for oil dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tawfi\\Thesis\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tawfi\\Thesis\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tawfi\\Thesis\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tawfi\\Thesis\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e64372ad6c4fe6af5fa41556641f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before augmentation: {-1: 896, 1: 41}\n",
      "Class distribution after augmentation: {-1.0: 896, 1.0: 82}\n",
      "Precision score (original data): 0.6000\n",
      "Precision score (generated data): 0.8750\n",
      "Recall score (original data): 0.2727\n",
      "Recall score (generated data): 0.6364\n",
      "F1 score (original data): 0.3750\n",
      "F1 score (generated data): 0.7368\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.99      0.98       271\n",
      "           1       0.60      0.27      0.37        11\n",
      "\n",
      "    accuracy                           0.96       282\n",
      "   macro avg       0.79      0.63      0.68       282\n",
      "weighted avg       0.96      0.96      0.96       282\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      0.99       271\n",
      "           1       0.88      0.64      0.74        11\n",
      "\n",
      "    accuracy                           0.98       282\n",
      "   macro avg       0.93      0.82      0.86       282\n",
      "weighted avg       0.98      0.98      0.98       282\n",
      "\n",
      "Number of fake samples generated: 41\n",
      "Result Metrics for AutoDiff Autoencoder & ForestDIffusion for mammography dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8d849635fd40d6884a61bfe9a05633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before augmentation: {-1: 10923, 1: 260}\n",
      "Class distribution after augmentation: {-1.0: 10923, 1.0: 360}\n",
      "Precision score (original data): 0.9167\n",
      "Precision score (generated data): 0.9661\n",
      "Recall score (original data): 0.5946\n",
      "Recall score (generated data): 0.7703\n",
      "F1 score (original data): 0.7213\n",
      "F1 score (generated data): 0.8571\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      0.99      3281\n",
      "           1       0.92      0.59      0.72        74\n",
      "\n",
      "    accuracy                           0.99      3355\n",
      "   macro avg       0.95      0.80      0.86      3355\n",
      "weighted avg       0.99      0.99      0.99      3355\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      1.00      3281\n",
      "           1       0.97      0.77      0.86        74\n",
      "\n",
      "    accuracy                           0.99      3355\n",
      "   macro avg       0.98      0.88      0.93      3355\n",
      "weighted avg       0.99      0.99      0.99      3355\n",
      "\n",
      "Number of fake samples generated: 100\n",
      "Result Metrics for AutoDiff Autoencoder & ForestDIffusion for HTRU dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8452e42782427daf4da5f4525e457e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before augmentation: {0: 16259, 1: 1639}\n",
      "Class distribution after augmentation: {0.0: 16259, 1.0: 1739}\n",
      "Precision score (original data): 0.9376\n",
      "Precision score (generated data): 0.9794\n",
      "Recall score (original data): 0.8354\n",
      "Recall score (generated data): 0.8786\n",
      "F1 score (original data): 0.8836\n",
      "F1 score (generated data): 0.9262\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      4884\n",
      "           1       0.94      0.84      0.88       486\n",
      "\n",
      "    accuracy                           0.98      5370\n",
      "   macro avg       0.96      0.91      0.94      5370\n",
      "weighted avg       0.98      0.98      0.98      5370\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4884\n",
      "           1       0.98      0.88      0.93       486\n",
      "\n",
      "    accuracy                           0.99      5370\n",
      "   macro avg       0.98      0.94      0.96      5370\n",
      "weighted avg       0.99      0.99      0.99      5370\n",
      "\n",
      "Number of fake samples generated: 100\n",
      "Result Metrics for AutoDiff Autoencoder & ForestDIffusion for diabetes dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d230e2857e9e4bcdadf37f9f71b86f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before augmentation: {0: 500, 1: 268}\n",
      "Class distribution after augmentation: {0.0: 500, 1.0: 368}\n",
      "Precision score (original data): 0.6386\n",
      "Precision score (generated data): 0.7204\n",
      "Recall score (original data): 0.6625\n",
      "Recall score (generated data): 0.8375\n",
      "F1 score (original data): 0.6503\n",
      "F1 score (generated data): 0.7746\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81       151\n",
      "           1       0.64      0.66      0.65        80\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.73      0.73      0.73       231\n",
      "weighted avg       0.76      0.75      0.75       231\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87       151\n",
      "           1       0.72      0.84      0.77        80\n",
      "\n",
      "    accuracy                           0.83       231\n",
      "   macro avg       0.81      0.83      0.82       231\n",
      "weighted avg       0.84      0.83      0.83       231\n",
      "\n",
      "Number of fake samples generated: 100\n",
      "Result Metrics for AutoDiff Autoencoder & ForestDIffusion for creditcard_sampled dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a11c754d064548b6655a910c0deaaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before augmentation: {0: 4000, 1: 50}\n",
      "Class distribution after augmentation: {0.0: 4000, 1.0: 100}\n",
      "Precision score (original data): 0.8667\n",
      "Precision score (generated data): 0.8750\n",
      "Recall score (original data): 0.7647\n",
      "Recall score (generated data): 0.8235\n",
      "F1 score (original data): 0.8125\n",
      "F1 score (generated data): 0.8485\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1198\n",
      "           1       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           1.00      1215\n",
      "   macro avg       0.93      0.88      0.90      1215\n",
      "weighted avg       0.99      1.00      0.99      1215\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1198\n",
      "           1       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           1.00      1215\n",
      "   macro avg       0.94      0.91      0.92      1215\n",
      "weighted avg       1.00      1.00      1.00      1215\n",
      "\n",
      "Number of fake samples generated: 50\n",
      "              Dataset  Precision_Original  Recall_Original  F1_Original  \\\n",
      "0   yeast_ml8_dataset            0.000000         0.000000     0.000000   \n",
      "1                 oil            0.600000         0.272727     0.375000   \n",
      "2         mammography            0.916667         0.594595     0.721311   \n",
      "3                HTRU            0.937644         0.835391     0.883569   \n",
      "4            diabetes            0.638554         0.662500     0.650307   \n",
      "5  creditcard_sampled            0.866667         0.764706     0.812500   \n",
      "\n",
      "   Precision_Generated  Recall_Generated  F1_Generated  Num_Fake_Samples  \n",
      "0             1.000000          0.551020      0.710526               100  \n",
      "1             0.875000          0.636364      0.736842                41  \n",
      "2             0.966102          0.770270      0.857143               100  \n",
      "3             0.979358          0.878601      0.926247               100  \n",
      "4             0.720430          0.837500      0.774566               100  \n",
      "5             0.875000          0.823529      0.848485                50  \n"
     ]
    }
   ],
   "source": [
    "strings_set = ['diabetes','oil','yeast_ml8_dataset','creditcard_sampled','HTRU','mammography']\n",
    "Model = 'AutoDiff'\n",
    "metrics_list = []\n",
    "\n",
    "\n",
    "for dataset in strings_set:\n",
    "    print(f\"Result Metrics for AutoDiff Autoencoder & ForestDIffusion for {dataset} dataset\")\n",
    "    file_path = f'..\\\\..\\\\..\\\\Datasets\\\\Original Data\\\\{dataset}.csv'\n",
    "    # Read dataframe\n",
    "    # print(file_path)\n",
    "    real_df = pd.read_csv(file_path)\n",
    "    #real_df = real_df.drop('url', axis=1)\n",
    "    # # Step 2: Inspect the data and check for class imbalance\n",
    "    # # Assuming the last column is the label, and the rest are features\n",
    "    X = real_df.iloc[:, :-1].values  # Features\n",
    "    y = real_df.iloc[:, -1].values  # Labels (binary classification)\n",
    "    #  # Separate the minority class\n",
    "    # Find the minority class\n",
    "    \n",
    "    real_minortiy = real_df[y == 1]\n",
    "\n",
    "    threshold = 0.01 # Threshold for mixed-type variables\n",
    "    parser = pce.DataFrameParser().fit(real_minortiy, threshold)\n",
    "    ################################################################################################################\n",
    "    # Auto-encoder hyper-parameters\n",
    "    device = 'cuda' #@param {'type':'string'}\n",
    "    n_epochs = 2000 #@param {'type':'integer'}\n",
    "    eps = 1e-5 #@param {type:\"number\"}\n",
    "    weight_decay = 1e-6 #@param {'type':'number'}\n",
    "    maximum_learning_rate = 1e-2 #@param {'type':'number'}\n",
    "    lr = 2e-4 #@param {'type':'number'}\n",
    "    hidden_size = 250\n",
    "    num_layers = 3\n",
    "    batch_size = real_minortiy.shape[0] # Full batch\n",
    "\n",
    "    ds = ae.train_autoencoder(real_minortiy, hidden_size, num_layers, lr, weight_decay, n_epochs, batch_size, threshold)\n",
    "    latent_features = ds[1].detach()\n",
    "\n",
    "    from ForestDiffusion import ForestDiffusionModel\n",
    "\n",
    "\n",
    "    # Convert to NumPy array\n",
    "    array = latent_features.detach().cpu().numpy()\n",
    "    forest_model = ForestDiffusionModel(array, label_y=None, n_t=50, duplicate_K=100, bin_indexes=[], cat_indexes=[], int_indexes=[], diffusion_type='flow', n_jobs=-1)\n",
    "    minority_fake = forest_model.generate(batch_size=len(real_minortiy)) # Adjust the batch size to create a balanced dataset\n",
    "    sample=torch.tensor(minority_fake, dtype=torch.float32)\n",
    "    sample.shape\n",
    "    gen_output = ds[0](sample, ds[2], ds[3])\n",
    "    gen_df = pce.convert_to_table(real_minortiy, gen_output, threshold)\n",
    "\n",
    "    output_directory =  f'..\\\\..\\\\..\\\\Datasets\\\\Synthetic Data\\\\'\n",
    "    filename = f'{Model}+Forest_{dataset}_Synthetic.csv'\n",
    "    output_file = os.path.join(output_directory, filename)\n",
    "    gen_df.to_csv(output_file, index=False) \n",
    "\n",
    "\n",
    "    # Select a random sample of the generated data\n",
    "    selected_samples = gen_df.sample(n=min(100,gen_df.shape[0]), random_state=42)  # For reproducibility\n",
    "    # Syn _df will be the dataset after augmentation\n",
    "    syn_df = pd.concat([real_df, selected_samples], ignore_index=True)\n",
    "\n",
    "\n",
    "    augmented_output_directory =  f'..\\\\..\\\\..\\\\Datasets\\\\Augmented Data\\\\'\n",
    "    filename = f'{Model}+Forest_{dataset}_Augmented.csv'\n",
    "    augmented_output_file = os.path.join(augmented_output_directory, filename)\n",
    "    syn_df.to_csv(augmented_output_file, index=False) \n",
    "\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from ForestDiffusion import ForestDiffusionModel\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "    # real_df = pd.read_csv(filename)\n",
    "    # syn_filename = f'{string}/{Model}_{string}_Augmented.csv'\n",
    "\n",
    "    # augmented_df = pd.read_csv(syn_filename)\n",
    "    augmented_df=syn_df\n",
    "\n",
    "    X = real_df.iloc[:, :-1].values  # Features\n",
    "    y = real_df.iloc[:, -1].values \n",
    "    # Check and print the original class distribution\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    class_dist_before = dict(zip(unique, counts))\n",
    "    print(f\"Class distribution before augmentation: {class_dist_before}\")# Labels (binary classification)\n",
    "\n",
    "    X_balanced = augmented_df.iloc[:, :-1].values  # Features\n",
    "    y_balanced = augmented_df.iloc[:, -1].values  # Labels (binary classification)\n",
    "\n",
    "    # Check and print the Augmented class distribution\n",
    "    unique, counts = np.unique(y_balanced, return_counts=True)\n",
    "    class_dist_after = dict(zip(unique, counts))\n",
    "    print(f\"Class distribution after augmentation: {class_dist_after}\")\n",
    "\n",
    "    # Step 6: Split the dataset into training and test sets (original and balanced)\n",
    "    X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_balanced, y_balanced, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Step 7: Train a simple classifier on both original and generated datasets\n",
    "    clf_orig = RandomForestClassifier(random_state=42)\n",
    "    clf_orig.fit(X_train_orig, y_train_orig)\n",
    "\n",
    "    clf_bal = RandomForestClassifier(random_state=42)\n",
    "    clf_bal.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "    # Step 8: Predict and calculate recall and F1 scores\n",
    "    y_pred_orig = clf_orig.predict(X_test_orig)\n",
    "    y_pred_bal = clf_bal.predict(X_test_orig)\n",
    "\n",
    "    prec_orig = precision_score(y_test_orig, y_pred_orig)\n",
    "    prec_bal = precision_score(y_test_orig, y_pred_bal)\n",
    "    \n",
    "    recall_orig = recall_score(y_test_orig, y_pred_orig)\n",
    "    recalls_bal = recall_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "    f1_orig = f1_score(y_test_orig, y_pred_orig)\n",
    "    f1_bal = f1_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "    # Step 9: Print and store the performance metrics\n",
    "    # Store metrics in a dictionary\n",
    "    metrics = {\n",
    "    \"Dataset\": dataset,\n",
    "    \"Precision_Original\": prec_orig,\n",
    "    \"Precision_Generated\": prec_bal,\n",
    "    \"Recall_Original\": recall_orig,\n",
    "    \"Recall_Generated\": recalls_bal,\n",
    "    \"F1_Original\": f1_orig,   \n",
    "    \"F1_Generated\": f1_bal,\n",
    "    \"Num_Fake_Samples\": len(augmented_df) - len(real_df),\n",
    "    \"Synthetic/Original_Ratio\": 100*(len(augmented_df) - len(real_df))/len(real_minortiy)\n",
    "    }\n",
    "\n",
    "    # Append the dictionary to the list\n",
    "    metrics_list.append(metrics)\n",
    "\n",
    "    print(f\"Precision score (original data): {prec_orig:.4f}\")\n",
    "    print(f\"Precision score (generated data): {prec_bal:.4f}\")\n",
    "    print(f\"Recall score (original data): {recall_orig:.4f}\")\n",
    "    print(f\"Recall score (generated data): {recalls_bal:.4f}\")\n",
    "    print(f\"F1 score (original data): {f1_orig:.4f}\")\n",
    "    print(f\"F1 score (generated data): {f1_bal:.4f}\")\n",
    "    print(\"Classification Report (original data):\\n\", classification_report(y_test_orig, y_pred_orig))\n",
    "    print(\"Classification Report (generated data):\\n\", classification_report(y_test_orig, y_pred_bal))\n",
    "\n",
    "\n",
    "    print(f\"Number of fake samples generated: {len(augmented_df)-len(real_df)}\")\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "metrics_df.to_csv(\"Auto_Diff_Forest_different_datasets_metric.csv\", index=False)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Precision_Original</th>\n",
       "      <th>Recall_Original</th>\n",
       "      <th>F1_Original</th>\n",
       "      <th>Precision_Generated</th>\n",
       "      <th>Recall_Generated</th>\n",
       "      <th>F1_Generated</th>\n",
       "      <th>Num_Fake_Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yeast_ml8_dataset</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.551020</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oil</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mammography</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.770270</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HTRU</td>\n",
       "      <td>0.937644</td>\n",
       "      <td>0.835391</td>\n",
       "      <td>0.883569</td>\n",
       "      <td>0.979358</td>\n",
       "      <td>0.878601</td>\n",
       "      <td>0.926247</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.650307</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.774566</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>creditcard_sampled</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dataset  Precision_Original  Recall_Original  F1_Original  \\\n",
       "0   yeast_ml8_dataset            0.000000         0.000000     0.000000   \n",
       "1                 oil            0.600000         0.272727     0.375000   \n",
       "2         mammography            0.916667         0.594595     0.721311   \n",
       "3                HTRU            0.937644         0.835391     0.883569   \n",
       "4            diabetes            0.638554         0.662500     0.650307   \n",
       "5  creditcard_sampled            0.866667         0.764706     0.812500   \n",
       "\n",
       "   Precision_Generated  Recall_Generated  F1_Generated  Num_Fake_Samples  \n",
       "0             1.000000          0.551020      0.710526               100  \n",
       "1             0.875000          0.636364      0.736842                41  \n",
       "2             0.966102          0.770270      0.857143               100  \n",
       "3             0.979358          0.878601      0.926247               100  \n",
       "4             0.720430          0.837500      0.774566               100  \n",
       "5             0.875000          0.823529      0.848485                50  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "metrics_df=pd.read_csv(\"Auto_Diff_Forest_different_datasets_metric.csv\")\n",
    "metrics_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Precision_Original</th>\n",
       "      <th>Recall_Original</th>\n",
       "      <th>F1_Original</th>\n",
       "      <th>Precision_Generated</th>\n",
       "      <th>Recall_Generated</th>\n",
       "      <th>F1_Generated</th>\n",
       "      <th>Num_Fake_Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>creditcard_sampled</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dataset  Precision_Original  Recall_Original  F1_Original  \\\n",
       "5  creditcard_sampled            0.866667         0.764706       0.8125   \n",
       "\n",
       "   Precision_Generated  Recall_Generated  F1_Generated  Num_Fake_Samples  \n",
       "5                0.875          0.823529      0.848485                50  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df[metrics_df['Dataset']=='creditcard_sampled'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Metrics for AutoDiff Autoencoder & ForestDIffusion for reduced_diabetes dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d0d8667e6d48f891ae96da7faee7e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before augmentation: {0: 500, 1: 60}\n",
      "Class distribution after augmentation: {0.0: 500, 1.0: 120}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "# Define the path to your folder\n",
    "folder_path = f'..\\\\..\\\\..\\\\Models\\\\AutoDiffusion' \n",
    "\n",
    "# Add the folder to sys.path\n",
    "sys.path.append(folder_path)\n",
    "strings_set = ['reduced_diabetes']\n",
    "Model = 'AutoDiff'\n",
    "metrics_list = []\n",
    "import numpy as np\n",
    "#import process_edited as pce\n",
    "import process_GQ as pce\n",
    "import autoencoder as ae\n",
    "import diffusion as diff\n",
    "import TabDDPMdiff as TabDiff\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for dataset in strings_set:\n",
    "    print(f\"Result Metrics for AutoDiff Autoencoder & ForestDIffusion for {dataset} dataset\")\n",
    "    file_path = f'..\\\\..\\\\..\\\\Datasets\\\\Original Data\\\\{dataset}.csv'\n",
    "    # Read dataframe\n",
    "    # print(file_path)\n",
    "    real_df = pd.read_csv(file_path)\n",
    "    #real_df = real_df.drop('url', axis=1)\n",
    "    # # Step 2: Inspect the data and check for class imbalance\n",
    "    # # Assuming the last column is the label, and the rest are features\n",
    "    X = real_df.iloc[:, :-1].values  # Features\n",
    "    y = real_df.iloc[:, -1].values  # Labels (binary classification)\n",
    "    #  # Separate the minority class\n",
    "    # Find the minority class\n",
    "    \n",
    "    real_minortiy = real_df[y == 1]\n",
    "\n",
    "    threshold = 0.01 # Threshold for mixed-type variables\n",
    "    parser = pce.DataFrameParser().fit(real_minortiy, threshold)\n",
    "    ################################################################################################################\n",
    "    # Auto-encoder hyper-parameters\n",
    "    device = 'cuda' #@param {'type':'string'}\n",
    "    n_epochs = 2000 #@param {'type':'integer'}\n",
    "    eps = 1e-5 #@param {type:\"number\"}\n",
    "    weight_decay = 1e-6 #@param {'type':'number'}\n",
    "    maximum_learning_rate = 1e-2 #@param {'type':'number'}\n",
    "    lr = 2e-4 #@param {'type':'number'}\n",
    "    hidden_size = 250\n",
    "    num_layers = 3\n",
    "    batch_size = real_minortiy.shape[0] # Full batch\n",
    "\n",
    "    ds = ae.train_autoencoder(real_minortiy, hidden_size, num_layers, lr, weight_decay, n_epochs, batch_size, threshold)\n",
    "    latent_features = ds[1].detach()\n",
    "\n",
    "    from ForestDiffusion import ForestDiffusionModel\n",
    "\n",
    "\n",
    "    # Convert to NumPy array\n",
    "    array = latent_features.detach().cpu().numpy()\n",
    "    forest_model = ForestDiffusionModel(array, label_y=None, n_t=50, duplicate_K=100, bin_indexes=[], cat_indexes=[], int_indexes=[], diffusion_type='flow', n_jobs=-1)\n",
    "    minority_fake = forest_model.generate(batch_size=60) # Adjust the batch size to create a balanced dataset\n",
    "    sample=torch.tensor(minority_fake, dtype=torch.float32)\n",
    "    sample.shape\n",
    "    gen_output = ds[0](sample, ds[2], ds[3])\n",
    "    gen_df = pce.convert_to_table(real_minortiy, gen_output, threshold)\n",
    "\n",
    "    output_directory =  f'..\\\\..\\\\..\\\\Datasets\\\\Synthetic Data\\\\'\n",
    "    filename = f'{Model}+Forest_{dataset}_Synthetic.csv'\n",
    "    output_file = os.path.join(output_directory, filename)\n",
    "    gen_df.to_csv(output_file, index=False) \n",
    "\n",
    "\n",
    "    # Select a random sample of the generated data\n",
    "    selected_samples = gen_df.sample(n=min(100,gen_df.shape[0]), random_state=42)  # For reproducibility\n",
    "    # Syn _df will be the dataset after augmentation\n",
    "    syn_df = pd.concat([real_df, selected_samples], ignore_index=True)\n",
    "\n",
    "\n",
    "    # augmented_output_directory =  f'..\\\\..\\\\..\\\\Datasets\\\\Augmented Data\\\\'\n",
    "    # filename = f'{Model}+Forest_{dataset}_Augmented.csv'\n",
    "    # augmented_output_file = os.path.join(augmented_output_directory, filename)\n",
    "    # syn_df.to_csv(augmented_output_file, index=False) \n",
    "\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from ForestDiffusion import ForestDiffusionModel\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "    # real_df = pd.read_csv(filename)\n",
    "    # syn_filename = f'{string}/{Model}_{string}_Augmented.csv'\n",
    "\n",
    "    # augmented_df = pd.read_csv(syn_filename)\n",
    "    augmented_df=syn_df\n",
    "\n",
    "    X = real_df.iloc[:, :-1].values  # Features\n",
    "    y = real_df.iloc[:, -1].values \n",
    "    # Check and print the original class distribution\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    class_dist_before = dict(zip(unique, counts))\n",
    "    print(f\"Class distribution before augmentation: {class_dist_before}\")# Labels (binary classification)\n",
    "\n",
    "    X_balanced = augmented_df.iloc[:, :-1].values  # Features\n",
    "    y_balanced = augmented_df.iloc[:, -1].values  # Labels (binary classification)\n",
    "\n",
    "    # Check and print the Augmented class distribution\n",
    "    unique, counts = np.unique(y_balanced, return_counts=True)\n",
    "    class_dist_after = dict(zip(unique, counts))\n",
    "    print(f\"Class distribution after augmentation: {class_dist_after}\")\n",
    "\n",
    "    # Step 6: Split the dataset into training and test sets (original and balanced)\n",
    "    X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_balanced, y_balanced, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Step 7: Train a simple classifier on both original and generated datasets\n",
    "    clf_orig = RandomForestClassifier(random_state=42)\n",
    "    clf_orig.fit(X_train_orig, y_train_orig)\n",
    "\n",
    "    clf_bal = RandomForestClassifier(random_state=42)\n",
    "    clf_bal.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "    # Step 8: Predict and calculate recall and F1 scores\n",
    "    y_pred_orig = clf_orig.predict(X_test_orig)\n",
    "    y_pred_bal = clf_bal.predict(X_test_orig)\n",
    "\n",
    "    prec_orig = precision_score(y_test_orig, y_pred_orig)\n",
    "    prec_bal = precision_score(y_test_orig, y_pred_bal)\n",
    "    \n",
    "    recall_orig = recall_score(y_test_orig, y_pred_orig)\n",
    "    recalls_bal = recall_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "    f1_orig = f1_score(y_test_orig, y_pred_orig)\n",
    "    f1_bal = f1_score(y_test_orig, y_pred_bal)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "augmented_df.to_csv('augmented_dataset__(from autodiffusion paper)autoencoder-forest_reduced_diabetes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Result Metrics for Audiff Paper Autoencoder+ForestDiffusion for reduced_diabetes dataset\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       151\n",
      "           1       0.43      0.18      0.25        17\n",
      "\n",
      "    accuracy                           0.89       168\n",
      "   macro avg       0.67      0.57      0.60       168\n",
      "weighted avg       0.86      0.89      0.87       168\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       151\n",
      "           1       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       168\n",
      "   macro avg       0.93      0.93      0.93       168\n",
      "weighted avg       0.98      0.98      0.98       168\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"# Result Metrics for Audiff Paper Autoencoder+ForestDiffusion for {dataset} dataset\")\n",
    "print(\"Classification Report (original data):\\n\", classification_report(y_test_orig, y_pred_orig))\n",
    "print(\"Classification Report (generated data):\\n\", classification_report(y_test_orig, y_pred_bal))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
