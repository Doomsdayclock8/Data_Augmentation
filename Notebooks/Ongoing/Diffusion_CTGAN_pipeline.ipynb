{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Diffusion Model with with CTGAN in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "# Plot the original data showing both classes\n",
    "sns.countplot(x='Class', data=df)\n",
    "plt.title(\"Original Dataset Class Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Split data into features and labels\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "# Normalize the features\n",
    "X = (X - X.mean()) / X.std()\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define MLP Diffusion Model\n",
    "class MLPDiffusion(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLPDiffusion, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, input_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Instantiate and train the diffusion model\n",
    "input_dim = X_tensor.shape[1]\n",
    "mlp_diffusion = MLPDiffusion(input_dim)\n",
    "optimizer = optim.Adam(mlp_diffusion.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train the model\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for batch_X, _ in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = mlp_diffusion(batch_X)\n",
    "        loss = criterion(output, batch_X)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Generate 200 synthetic samples using the trained diffusion model\n",
    "generated_data = mlp_diffusion(torch.randn(200, input_dim)).detach().numpy()\n",
    "generated_df = pd.DataFrame(generated_data, columns=X.columns)\n",
    "\n",
    "# Define metadata for the CTGAN synthesizer\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_csv(filepath='creditcard.csv')\n",
    "\n",
    "# Train CTGAN on the generated data using sdv\n",
    "synthesizer = CTGANSynthesizer(\n",
    "    metadata,\n",
    "    enforce_rounding=False,\n",
    "    epochs=500,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "synthesizer.fit(generated_df)\n",
    "\n",
    "# Generate 500 more synthetic samples using CTGAN\n",
    "ctgan_generated_data = synthesizer.sample(num_rows=500)\n",
    "ctgan_generated_df = pd.DataFrame(ctgan_generated_data, columns=X.columns)\n",
    "\n",
    "# Merge the original dataset with generated data\n",
    "augmented_df = pd.concat([df, generated_df, ctgan_generated_df], ignore_index=True)\n",
    "\n",
    "# Plot the augmented data showing both classes\n",
    "sns.countplot(x='Class', data=augmented_df)\n",
    "plt.title(\"Augmented Dataset Class Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Split augmented data into features and labels\n",
    "X_augmented = augmented_df.drop(columns=['Class'])\n",
    "y_augmented = augmented_df['Class']\n",
    "\n",
    "# Random Forest classification on original data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Classification Report on Original Data:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Random Forest classification on augmented data\n",
    "rf2= RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf2.fit(X_augmented, y_augmented)\n",
    "y_aug_pred = rf.predict(X_test)\n",
    "print(\"Classification Report on Augmented Data:\")\n",
    "print(classification_report(y_aug_test, y_aug_pred))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
