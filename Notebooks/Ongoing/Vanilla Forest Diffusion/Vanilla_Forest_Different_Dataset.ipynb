{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook tries to augment data using forest diffusion on datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Result Metrics for Vanilla ForestDiffusion for HTRU dataset\n",
      "Class distribution before augmentation: {0: 16259, 1: 1639}\n",
      "Class distribution after augmentation: {0.0: 16259, 1.0: 1739}\n",
      "Precision score (original data): 0.9376\n",
      "Precision score (generated data): 0.9703\n",
      "Recall score (original data): 0.8354\n",
      "Recall score (generated data): 0.8745\n",
      "F1 score (original data): 0.8836\n",
      "F1 score (generated data): 0.9199\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      4884\n",
      "           1       0.94      0.84      0.88       486\n",
      "\n",
      "    accuracy                           0.98      5370\n",
      "   macro avg       0.96      0.91      0.94      5370\n",
      "weighted avg       0.98      0.98      0.98      5370\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4884\n",
      "           1       0.97      0.87      0.92       486\n",
      "\n",
      "    accuracy                           0.99      5370\n",
      "   macro avg       0.98      0.94      0.96      5370\n",
      "weighted avg       0.99      0.99      0.99      5370\n",
      "\n",
      "Number of fake samples generated: 100\n",
      "# Result Metrics for Vanilla ForestDiffusion for oil dataset\n",
      "Class distribution before augmentation: {-1: 896, 1: 41}\n",
      "Class distribution after augmentation: {-1.0: 896, 1.0: 141}\n",
      "Precision score (original data): 0.6000\n",
      "Precision score (generated data): 0.9000\n",
      "Recall score (original data): 0.2727\n",
      "Recall score (generated data): 0.8182\n",
      "F1 score (original data): 0.3750\n",
      "F1 score (generated data): 0.8571\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.99      0.98       271\n",
      "           1       0.60      0.27      0.38        11\n",
      "\n",
      "    accuracy                           0.96       282\n",
      "   macro avg       0.79      0.63      0.68       282\n",
      "weighted avg       0.96      0.96      0.96       282\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      0.99       271\n",
      "           1       0.90      0.82      0.86        11\n",
      "\n",
      "    accuracy                           0.99       282\n",
      "   macro avg       0.95      0.91      0.93       282\n",
      "weighted avg       0.99      0.99      0.99       282\n",
      "\n",
      "Number of fake samples generated: 100\n",
      "# Result Metrics for Vanilla ForestDiffusion for mammography dataset\n",
      "Class distribution before augmentation: {-1: 10923, 1: 260}\n",
      "Class distribution after augmentation: {-1.0: 10923, 1.0: 360}\n",
      "Precision score (original data): 0.9167\n",
      "Precision score (generated data): 0.9643\n",
      "Recall score (original data): 0.5946\n",
      "Recall score (generated data): 0.7297\n",
      "F1 score (original data): 0.7213\n",
      "F1 score (generated data): 0.8308\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      0.99      3281\n",
      "           1       0.92      0.59      0.72        74\n",
      "\n",
      "    accuracy                           0.99      3355\n",
      "   macro avg       0.95      0.80      0.86      3355\n",
      "weighted avg       0.99      0.99      0.99      3355\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      1.00      3281\n",
      "           1       0.96      0.73      0.83        74\n",
      "\n",
      "    accuracy                           0.99      3355\n",
      "   macro avg       0.98      0.86      0.91      3355\n",
      "weighted avg       0.99      0.99      0.99      3355\n",
      "\n",
      "Number of fake samples generated: 100\n",
      "# Result Metrics for Vanilla ForestDiffusion for creditcard_sampled dataset\n",
      "Class distribution before augmentation: {0: 4000, 1: 50}\n",
      "Class distribution after augmentation: {0.0: 4000, 1.0: 150}\n",
      "Precision score (original data): 0.8667\n",
      "Precision score (generated data): 0.8824\n",
      "Recall score (original data): 0.7647\n",
      "Recall score (generated data): 0.8824\n",
      "F1 score (original data): 0.8125\n",
      "F1 score (generated data): 0.8824\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1198\n",
      "           1       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           1.00      1215\n",
      "   macro avg       0.93      0.88      0.90      1215\n",
      "weighted avg       0.99      1.00      0.99      1215\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1198\n",
      "           1       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           1.00      1215\n",
      "   macro avg       0.94      0.94      0.94      1215\n",
      "weighted avg       1.00      1.00      1.00      1215\n",
      "\n",
      "Number of fake samples generated: 100\n",
      "# Result Metrics for Vanilla ForestDiffusion for diabetes dataset\n",
      "Class distribution before augmentation: {0: 500, 1: 268}\n",
      "Class distribution after augmentation: {0.0: 500, 1.0: 368}\n",
      "Precision score (original data): 0.6386\n",
      "Precision score (generated data): 0.7356\n",
      "Recall score (original data): 0.6625\n",
      "Recall score (generated data): 0.8000\n",
      "F1 score (original data): 0.6503\n",
      "F1 score (generated data): 0.7665\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81       151\n",
      "           1       0.64      0.66      0.65        80\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.73      0.73      0.73       231\n",
      "weighted avg       0.76      0.75      0.75       231\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87       151\n",
      "           1       0.74      0.80      0.77        80\n",
      "\n",
      "    accuracy                           0.83       231\n",
      "   macro avg       0.81      0.82      0.82       231\n",
      "weighted avg       0.84      0.83      0.83       231\n",
      "\n",
      "Number of fake samples generated: 100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ForestDiffusion import ForestDiffusionModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "\n",
    "metrics_list = []\n",
    "# Step 1: Load the CSV file\n",
    "#file_path = 'creditcard.csv'  # Update this path to your local CSV file\n",
    "# strings_set = {'diabetes','oil','yeast_ml8_dataset','creditcard_sampled','HTRU','mammography'}\n",
    "strings_set = {'diabetes','oil','creditcard_sampled','HTRU','mammography'}\n",
    "for dataset in strings_set:\n",
    "    print(f\"# Result Metrics for Vanilla ForestDiffusion for {dataset} dataset\")\n",
    "    file_path = f'..\\\\..\\\\..\\\\Datasets\\\\Original Data\\\\{dataset}.csv'\n",
    "    \n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Step 2: Inspect the data and check for class imbalance\n",
    "    # Assuming the last column is the label, and the rest are features\n",
    "    X = data.iloc[:, :-1].values  # Features\n",
    "    y = data.iloc[:, -1].values  # Labels (binary classification)\n",
    "\n",
    "    # Check and print the original class distribution\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    class_dist_before = dict(zip(unique, counts))\n",
    "    print(f\"Class distribution before augmentation: {class_dist_before}\")\n",
    "\n",
    "    # # Step 3: Plot the original imbalanced data (first two features for visualization)\n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', label='Original Data', s=1)\n",
    "    # plt.title('Original Imbalanced Data')\n",
    "    # plt.xlabel('Feature 1')\n",
    "    # plt.ylabel('Feature 2')\n",
    "    # plt.show()\n",
    "\n",
    "    # Separate the minority class\n",
    "    X_minority = X[y == 1]\n",
    "    y_minority = y[y==1]\n",
    "    # Identify integer columns\n",
    "    int_columns = data.select_dtypes(include=['int']).columns\n",
    "    int_indexes = []\n",
    "    for col in int_columns:\n",
    "        col_index = data.columns.get_loc(col)\n",
    "        int_indexes.append(col_index)\n",
    "    import pandas as pd\n",
    "    # Step 4: Upsample the minority class using ForestDiffusionModel\n",
    "    forest_model = ForestDiffusionModel(X_minority, label_y=y_minority, n_t=50, duplicate_K=100, bin_indexes=[], cat_indexes=[], int_indexes=[], diffusion_type='flow', n_jobs=-1)\n",
    "    Xy_minority_fake = forest_model.generate(batch_size=100 )  # Adjust the batch size to create a balanced dataset\n",
    "    # Add generated samples to the main imbalanced dataset\n",
    "    X_minority_fake = Xy_minority_fake[:, :-1]   # Features\n",
    "    y_minority_fake = Xy_minority_fake[:, -1] # Labels (binary classification)\n",
    "    X_balanced = np.concatenate((X, X_minority_fake), axis=0)\n",
    "    y_balanced = np.concatenate((y, y_minority_fake), axis=0)\n",
    "    \n",
    "    # # Step 5: Plot the generated data (first two features for visualization)\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.scatter(X_balanced[:, 0], X_balanced[:, 1], c=y_balanced, cmap='viridis', label='Generated Data', s=1)\n",
    "    # plt.title('Data After Generation')\n",
    "    # plt.xlabel('Feature 1')\n",
    "    # plt.ylabel('Feature 2')\n",
    "    # plt.show()\n",
    "\n",
    "    # Check and print the class distribution after augmentation\n",
    "    unique_bal, counts_bal = np.unique(y_balanced, return_counts=True)\n",
    "    class_dist_after = dict(zip(unique_bal, counts_bal))\n",
    "    print(f\"Class distribution after augmentation: {class_dist_after}\")\n",
    "\n",
    "    # Step 6: Split the dataset into training and test sets (original and balanced)\n",
    "    X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_balanced, y_balanced, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Step 7: Train a simple classifier on both original and generated datasets\n",
    "    clf_orig = RandomForestClassifier(random_state=42)\n",
    "    clf_orig.fit(X_train_orig, y_train_orig)\n",
    "\n",
    "    clf_bal = RandomForestClassifier(random_state=42)\n",
    "    clf_bal.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "    # Step 8: Predict and calculate recall and F1 scores\n",
    "    y_pred_orig = clf_orig.predict(X_test_orig)\n",
    "    y_pred_bal = clf_bal.predict(X_test_orig)\n",
    "\n",
    "    prec_orig = precision_score(y_test_orig, y_pred_orig)\n",
    "    prec_bal = precision_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "\n",
    "    recall_orig = recall_score(y_test_orig, y_pred_orig)\n",
    "    recalls_bal = recall_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "    f1_orig = f1_score(y_test_orig, y_pred_orig)\n",
    "    f1_bal = f1_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "    # Step 9: Print the performance metrics\n",
    "    metrics = {\n",
    "        \"Dataset\": dataset,\n",
    "        \"Precision_Original\": prec_orig,\n",
    "        \"Recall_Original\": recall_orig,\n",
    "        \"F1_Original\": f1_orig,\n",
    "        \"Precision_Generated\": prec_bal,\n",
    "        \"Recall_Generated\": recalls_bal,\n",
    "        \"F1_Generated\": f1_bal,\n",
    "        \"Num_Fake_Samples\": len(X_balanced) - len(X),\n",
    "        \"Synthetic/Original_Ratio\":100*(len(X_balanced) - len(X))/len(Xy_minority_fake)\n",
    "    }\n",
    "\n",
    "    # Append the dictionary to the list\n",
    "    metrics_list.append(metrics)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f\"Precision score (original data): {prec_orig:.4f}\")\n",
    "    print(f\"Precision score (generated data): {prec_bal:.4f}\")\n",
    "    print(f\"Recall score (original data): {recall_orig:.4f}\")\n",
    "    print(f\"Recall score (generated data): {recalls_bal:.4f}\")\n",
    "    print(f\"F1 score (original data): {f1_orig:.4f}\")\n",
    "    print(f\"F1 score (generated data): {f1_bal:.4f}\")\n",
    "    print(\"Classification Report (original data):\\n\", classification_report(y_test_orig, y_pred_orig))\n",
    "    print(\"Classification Report (generated data):\\n\", classification_report(y_test_orig, y_pred_bal))\n",
    "\n",
    "    # Step 10: Print the number of fake samples generated\n",
    "    print(f\"Number of fake samples generated: {len(X_minority_fake)}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Dataset  Precision_Original  Recall_Original  F1_Original  \\\n",
      "0         mammography            0.916667         0.594595     0.721311   \n",
      "1                 oil            0.600000         0.272727     0.375000   \n",
      "2  creditcard_sampled            0.866667         0.764706     0.812500   \n",
      "3                HTRU            0.937644         0.835391     0.883569   \n",
      "4            diabetes            0.638554         0.662500     0.650307   \n",
      "\n",
      "   Precision_Generated  Recall_Generated  F1_Generated  Num_Fake_Samples  \\\n",
      "0             0.964286          0.729730      0.830769               100   \n",
      "1             0.900000          0.818182      0.857143               100   \n",
      "2             0.882353          0.882353      0.882353               100   \n",
      "3             0.970320          0.874486      0.919913               100   \n",
      "4             0.735632          0.800000      0.766467               100   \n",
      "\n",
      "   Synthetic/Original_Ratio  \n",
      "0                     100.0  \n",
      "1                     100.0  \n",
      "2                     100.0  \n",
      "3                     100.0  \n",
      "4                     100.0  \n"
     ]
    }
   ],
   "source": [
    "# Convert the list of dictionaries into a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "metrics_df.to_csv(\"Vanilla_Forest_different_datasets_metric.csv\", index=False)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Precision_Original</th>\n",
       "      <th>Recall_Original</th>\n",
       "      <th>F1_Original</th>\n",
       "      <th>Precision_Generated</th>\n",
       "      <th>Recall_Generated</th>\n",
       "      <th>F1_Generated</th>\n",
       "      <th>Num_Fake_Samples</th>\n",
       "      <th>Synthetic/Original_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>creditcard_sampled</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dataset  Precision_Original  Recall_Original  F1_Original  \\\n",
       "2  creditcard_sampled            0.866667         0.764706       0.8125   \n",
       "\n",
       "   Precision_Generated  Recall_Generated  F1_Generated  Num_Fake_Samples  \\\n",
       "2             0.882353          0.882353      0.882353               100   \n",
       "\n",
       "   Synthetic/Original_Ratio  \n",
       "2                     100.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df[metrics_df['Dataset']=='creditcard_sampled'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Precision_Original</th>\n",
       "      <th>Recall_Original</th>\n",
       "      <th>F1_Original</th>\n",
       "      <th>Precision_Generated</th>\n",
       "      <th>Recall_Generated</th>\n",
       "      <th>F1_Generated</th>\n",
       "      <th>Num_Fake_Samples</th>\n",
       "      <th>Synthetic/Original_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mammography</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oil</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>creditcard_sampled</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HTRU</td>\n",
       "      <td>0.937644</td>\n",
       "      <td>0.835391</td>\n",
       "      <td>0.883569</td>\n",
       "      <td>0.970320</td>\n",
       "      <td>0.874486</td>\n",
       "      <td>0.919913</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.650307</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.766467</td>\n",
       "      <td>100</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dataset  Precision_Original  Recall_Original  F1_Original  \\\n",
       "0         mammography            0.916667         0.594595     0.721311   \n",
       "1                 oil            0.600000         0.272727     0.375000   \n",
       "2  creditcard_sampled            0.866667         0.764706     0.812500   \n",
       "3                HTRU            0.937644         0.835391     0.883569   \n",
       "4            diabetes            0.638554         0.662500     0.650307   \n",
       "\n",
       "   Precision_Generated  Recall_Generated  F1_Generated  Num_Fake_Samples  \\\n",
       "0             0.964286          0.729730      0.830769               100   \n",
       "1             0.900000          0.818182      0.857143               100   \n",
       "2             0.882353          0.882353      0.882353               100   \n",
       "3             0.970320          0.874486      0.919913               100   \n",
       "4             0.735632          0.800000      0.766467               100   \n",
       "\n",
       "   Synthetic/Original_Ratio  \n",
       "0                     100.0  \n",
       "1                     100.0  \n",
       "2                     100.0  \n",
       "3                     100.0  \n",
       "4                     100.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Result Metrics for Vanilla ForestDiffusion for reduced_diabetes dataset\n",
      "Class distribution before augmentation: {0: 500, 1: 60}\n",
      "Class distribution after augmentation: {0.0: 500, 1.0: 120}\n",
      "Precision score (original data): 0.4286\n",
      "Precision score (generated data): 0.8750\n",
      "Recall score (original data): 0.1765\n",
      "Recall score (generated data): 0.8235\n",
      "F1 score (original data): 0.2500\n",
      "F1 score (generated data): 0.8485\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       151\n",
      "           1       0.43      0.18      0.25        17\n",
      "\n",
      "    accuracy                           0.89       168\n",
      "   macro avg       0.67      0.57      0.60       168\n",
      "weighted avg       0.86      0.89      0.87       168\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       151\n",
      "           1       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       168\n",
      "   macro avg       0.93      0.91      0.92       168\n",
      "weighted avg       0.97      0.97      0.97       168\n",
      "\n",
      "Number of fake samples generated: 60\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ForestDiffusion import ForestDiffusionModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "\n",
    "metrics_list = []\n",
    "# Step 1: Load the CSV file\n",
    "#file_path = 'creditcard.csv'  # Update this path to your local CSV file\n",
    "# strings_set = {'diabetes','oil','yeast_ml8_dataset','creditcard_sampled','HTRU','mammography'}\n",
    "strings_set = {'reduced_diabetes'}\n",
    "for dataset in strings_set:\n",
    "    print(f\"# Result Metrics for Vanilla ForestDiffusion for {dataset} dataset\")\n",
    "    file_path = f'..\\\\..\\\\..\\\\Datasets\\\\Original Data\\\\{dataset}.csv'\n",
    "    \n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Step 2: Inspect the data and check for class imbalance\n",
    "    # Assuming the last column is the label, and the rest are features\n",
    "    X = data.iloc[:, :-1].values  # Features\n",
    "    y = data.iloc[:, -1].values  # Labels (binary classification)\n",
    "\n",
    "    # Check and print the original class distribution\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    class_dist_before = dict(zip(unique, counts))\n",
    "    print(f\"Class distribution before augmentation: {class_dist_before}\")\n",
    "\n",
    "    # # Step 3: Plot the original imbalanced data (first two features for visualization)\n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', label='Original Data', s=1)\n",
    "    # plt.title('Original Imbalanced Data')\n",
    "    # plt.xlabel('Feature 1')\n",
    "    # plt.ylabel('Feature 2')\n",
    "    # plt.show()\n",
    "\n",
    "    # Separate the minority class\n",
    "    X_minority = X[y == 1]\n",
    "    y_minority = y[y==1]\n",
    "    # Identify integer columns\n",
    "    int_columns = data.select_dtypes(include=['int']).columns\n",
    "    int_indexes = []\n",
    "    for col in int_columns:\n",
    "        col_index = data.columns.get_loc(col)\n",
    "        int_indexes.append(col_index)\n",
    "    import pandas as pd\n",
    "    # Step 4: Upsample the minority class using ForestDiffusionModel\n",
    "    forest_model = ForestDiffusionModel(X_minority, label_y=y_minority, n_t=50, duplicate_K=100, bin_indexes=[], cat_indexes=[], int_indexes=[], diffusion_type='flow', n_jobs=-1)\n",
    "    Xy_minority_fake = forest_model.generate(batch_size=60)  # Adjust the batch size to create a balanced dataset\n",
    "    # Add generated samples to the main imbalanced dataset\n",
    "    X_minority_fake = Xy_minority_fake[:, :-1]   # Features\n",
    "    y_minority_fake = Xy_minority_fake[:, -1] # Labels (binary classification)\n",
    "    X_balanced = np.concatenate((X, X_minority_fake), axis=0)\n",
    "    y_balanced = np.concatenate((y, y_minority_fake), axis=0)\n",
    "    \n",
    "    # # Step 5: Plot the generated data (first two features for visualization)\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.scatter(X_balanced[:, 0], X_balanced[:, 1], c=y_balanced, cmap='viridis', label='Generated Data', s=1)\n",
    "    # plt.title('Data After Generation')\n",
    "    # plt.xlabel('Feature 1')\n",
    "    # plt.ylabel('Feature 2')\n",
    "    # plt.show()\n",
    "\n",
    "    # Check and print the class distribution after augmentation\n",
    "    unique_bal, counts_bal = np.unique(y_balanced, return_counts=True)\n",
    "    class_dist_after = dict(zip(unique_bal, counts_bal))\n",
    "    print(f\"Class distribution after augmentation: {class_dist_after}\")\n",
    "\n",
    "    # Step 6: Split the dataset into training and test sets (original and balanced)\n",
    "    X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_balanced, y_balanced, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Step 7: Train a simple classifier on both original and generated datasets\n",
    "    clf_orig = RandomForestClassifier(random_state=42)\n",
    "    clf_orig.fit(X_train_orig, y_train_orig)\n",
    "\n",
    "    clf_bal = RandomForestClassifier(random_state=42)\n",
    "    clf_bal.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "    # Step 8: Predict and calculate recall and F1 scores\n",
    "    y_pred_orig = clf_orig.predict(X_test_orig)\n",
    "    y_pred_bal = clf_bal.predict(X_test_orig)\n",
    "\n",
    "    prec_orig = precision_score(y_test_orig, y_pred_orig)\n",
    "    prec_bal = precision_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "\n",
    "    recall_orig = recall_score(y_test_orig, y_pred_orig)\n",
    "    recalls_bal = recall_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "    f1_orig = f1_score(y_test_orig, y_pred_orig)\n",
    "    f1_bal = f1_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "    # Step 9: Print the performance metrics\n",
    "    metrics = {\n",
    "        \"Dataset\": dataset,\n",
    "        \"Precision_Original\": prec_orig,\n",
    "        \"Recall_Original\": recall_orig,\n",
    "        \"F1_Original\": f1_orig,\n",
    "        \"Precision_Generated\": prec_bal,\n",
    "        \"Recall_Generated\": recalls_bal,\n",
    "        \"F1_Generated\": f1_bal,\n",
    "        \"Num_Fake_Samples\": len(X_balanced) - len(X),\n",
    "        \"Synthetic/Original_Ratio\":100*(len(X_balanced) - len(X))/len(Xy_minority_fake)\n",
    "    }\n",
    "\n",
    "    # Append the dictionary to the list\n",
    "    metrics_list.append(metrics)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f\"Precision score (original data): {prec_orig:.4f}\")\n",
    "    print(f\"Precision score (generated data): {prec_bal:.4f}\")\n",
    "    print(f\"Recall score (original data): {recall_orig:.4f}\")\n",
    "    print(f\"Recall score (generated data): {recalls_bal:.4f}\")\n",
    "    print(f\"F1 score (original data): {f1_orig:.4f}\")\n",
    "    print(f\"F1 score (generated data): {f1_bal:.4f}\")\n",
    "    print(\"Classification Report (original data):\\n\", classification_report(y_test_orig, y_pred_orig))\n",
    "    print(\"Classification Report (generated data):\\n\", classification_report(y_test_orig, y_pred_bal))\n",
    "\n",
    "    # Step 10: Print the number of fake samples generated\n",
    "    print(f\"Number of fake samples generated: {len(X_minority_fake)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming data is the existing dataframe with column names\n",
    "column_names = list(data.columns[:-1])  # Exclude the target column name\n",
    "target_column_name = data.columns[-1]  # Name of the target column\n",
    "\n",
    "# Create the DataFrame from X_balanced\n",
    "X_balanced_df = pd.DataFrame(X_balanced, columns=column_names)\n",
    "\n",
    "# Add the target column\n",
    "X_balanced_df[target_column_name] = y_balanced\n",
    "\n",
    "X_balanced_df.to_csv('augmented_dataset__only-forest_reduced_diabetes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
