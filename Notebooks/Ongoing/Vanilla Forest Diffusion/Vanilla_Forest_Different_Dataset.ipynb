{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook tries to augment data using forest diffusion on datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla ForestDiffusion on Oils dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Metrics for Vanilla ForestDIffusion for oil dataset\n",
      "Class distribution before augmentation: {-1: 896, 1: 41}\n",
      "Class distribution after augmentation: {-1.0: 896, 1.0: 141}\n",
      "Precision score (original data): 0.6000\n",
      "Precision score (generated data): 0.9000\n",
      "Recall score (original data): 0.2727\n",
      "Recall score (generated data): 0.8182\n",
      "F1 score (original data): 0.3750\n",
      "F1 score (generated data): 0.8571\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.99      0.98       271\n",
      "           1       0.60      0.27      0.37        11\n",
      "\n",
      "    accuracy                           0.96       282\n",
      "   macro avg       0.79      0.63      0.68       282\n",
      "weighted avg       0.96      0.96      0.96       282\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      0.99       271\n",
      "           1       0.90      0.82      0.86        11\n",
      "\n",
      "    accuracy                           0.99       282\n",
      "   macro avg       0.95      0.91      0.93       282\n",
      "weighted avg       0.99      0.99      0.99       282\n",
      "\n",
      "Number of fake samples generated: 100\n",
      "Result Metrics for Vanilla ForestDIffusion for creditcard_sampled dataset\n",
      "Class distribution before augmentation: {0: 4000, 1: 50}\n",
      "Class distribution after augmentation: {0.0: 4000, 1.0: 150}\n",
      "Precision score (original data): 0.8667\n",
      "Precision score (generated data): 0.8824\n",
      "Recall score (original data): 0.7647\n",
      "Recall score (generated data): 0.8824\n",
      "F1 score (original data): 0.8125\n",
      "F1 score (generated data): 0.8824\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1198\n",
      "           1       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           1.00      1215\n",
      "   macro avg       0.93      0.88      0.90      1215\n",
      "weighted avg       0.99      1.00      0.99      1215\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1198\n",
      "           1       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           1.00      1215\n",
      "   macro avg       0.94      0.94      0.94      1215\n",
      "weighted avg       1.00      1.00      1.00      1215\n",
      "\n",
      "Number of fake samples generated: 100\n",
      "Result Metrics for Vanilla ForestDIffusion for mammography dataset\n",
      "Class distribution before augmentation: {-1: 10923, 1: 260}\n",
      "Class distribution after augmentation: {-1.0: 10923, 1.0: 360}\n",
      "Precision score (original data): 0.9167\n",
      "Precision score (generated data): 0.9643\n",
      "Recall score (original data): 0.5946\n",
      "Recall score (generated data): 0.7297\n",
      "F1 score (original data): 0.7213\n",
      "F1 score (generated data): 0.8308\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      0.99      3281\n",
      "           1       0.92      0.59      0.72        74\n",
      "\n",
      "    accuracy                           0.99      3355\n",
      "   macro avg       0.95      0.80      0.86      3355\n",
      "weighted avg       0.99      0.99      0.99      3355\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.99      1.00      1.00      3281\n",
      "           1       0.96      0.73      0.83        74\n",
      "\n",
      "    accuracy                           0.99      3355\n",
      "   macro avg       0.98      0.86      0.91      3355\n",
      "weighted avg       0.99      0.99      0.99      3355\n",
      "\n",
      "Number of fake samples generated: 100\n",
      "Result Metrics for Vanilla ForestDIffusion for diabetes dataset\n",
      "Class distribution before augmentation: {0: 500, 1: 268}\n",
      "Class distribution after augmentation: {0.0: 500, 1.0: 368}\n",
      "Precision score (original data): 0.6386\n",
      "Precision score (generated data): 0.7356\n",
      "Recall score (original data): 0.6625\n",
      "Recall score (generated data): 0.8000\n",
      "F1 score (original data): 0.6503\n",
      "F1 score (generated data): 0.7665\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81       151\n",
      "           1       0.64      0.66      0.65        80\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.73      0.73      0.73       231\n",
      "weighted avg       0.76      0.75      0.75       231\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87       151\n",
      "           1       0.74      0.80      0.77        80\n",
      "\n",
      "    accuracy                           0.83       231\n",
      "   macro avg       0.81      0.82      0.82       231\n",
      "weighted avg       0.84      0.83      0.83       231\n",
      "\n",
      "Number of fake samples generated: 100\n",
      "Result Metrics for Vanilla ForestDIffusion for HTRU dataset\n",
      "Class distribution before augmentation: {0: 16259, 1: 1639}\n",
      "Class distribution after augmentation: {0.0: 16259, 1.0: 1739}\n",
      "Precision score (original data): 0.9376\n",
      "Precision score (generated data): 0.9703\n",
      "Recall score (original data): 0.8354\n",
      "Recall score (generated data): 0.8745\n",
      "F1 score (original data): 0.8836\n",
      "F1 score (generated data): 0.9199\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      4884\n",
      "           1       0.94      0.84      0.88       486\n",
      "\n",
      "    accuracy                           0.98      5370\n",
      "   macro avg       0.96      0.91      0.94      5370\n",
      "weighted avg       0.98      0.98      0.98      5370\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      4884\n",
      "           1       0.97      0.87      0.92       486\n",
      "\n",
      "    accuracy                           0.99      5370\n",
      "   macro avg       0.98      0.94      0.96      5370\n",
      "weighted avg       0.99      0.99      0.99      5370\n",
      "\n",
      "Number of fake samples generated: 100\n",
      "Result Metrics for Vanilla ForestDIffusion for yeast_ml8_dataset dataset\n",
      "Class distribution before augmentation: {-1: 2239, 1: 178}\n",
      "Class distribution after augmentation: {-1.0: 2239, 1.0: 278}\n",
      "Precision score (original data): 0.0000\n",
      "Precision score (generated data): 1.0000\n",
      "Recall score (original data): 0.0000\n",
      "Recall score (generated data): 0.5510\n",
      "F1 score (original data): 0.0000\n",
      "F1 score (generated data): 0.7105\n",
      "Classification Report (original data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      1.00      0.97       677\n",
      "           1       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.93       726\n",
      "   macro avg       0.47      0.50      0.48       726\n",
      "weighted avg       0.87      0.93      0.90       726\n",
      "\n",
      "Classification Report (generated data):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      1.00      0.98       677\n",
      "           1       1.00      0.55      0.71        49\n",
      "\n",
      "    accuracy                           0.97       726\n",
      "   macro avg       0.98      0.78      0.85       726\n",
      "weighted avg       0.97      0.97      0.97       726\n",
      "\n",
      "Number of fake samples generated: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tawfi\\Thesis\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tawfi\\Thesis\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tawfi\\Thesis\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tawfi\\Thesis\\env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ForestDiffusion import ForestDiffusionModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "# Step 1: Load the CSV file\n",
    "#file_path = 'creditcard.csv'  # Update this path to your local CSV file\n",
    "strings_set = {'diabetes','oil','yeast_ml8_dataset','creditcard_sampled','HTRU','mammography'}\n",
    "for dataset in strings_set:\n",
    "    print(f\"# Result Metrics for Vanilla ForestDiffusion for {dataset} dataset\")\n",
    "    file_path = f'..\\\\..\\\\..\\\\Datasets\\\\Original Data\\\\{dataset}.csv'\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Step 2: Inspect the data and check for class imbalance\n",
    "    # Assuming the last column is the label, and the rest are features\n",
    "    X = data.iloc[:, :-1].values  # Features\n",
    "    y = data.iloc[:, -1].values  # Labels (binary classification)\n",
    "\n",
    "    # Check and print the original class distribution\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    class_dist_before = dict(zip(unique, counts))\n",
    "    print(f\"Class distribution before augmentation: {class_dist_before}\")\n",
    "\n",
    "    # # Step 3: Plot the original imbalanced data (first two features for visualization)\n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', label='Original Data', s=1)\n",
    "    # plt.title('Original Imbalanced Data')\n",
    "    # plt.xlabel('Feature 1')\n",
    "    # plt.ylabel('Feature 2')\n",
    "    # plt.show()\n",
    "\n",
    "    # Separate the minority class\n",
    "    X_minority = X[y == 1]\n",
    "    y_minority = y[y==1]\n",
    "    # Identify integer columns\n",
    "    int_columns = data.select_dtypes(include=['int']).columns\n",
    "    int_indexes = []\n",
    "    for col in int_columns:\n",
    "        col_index = data.columns.get_loc(col)\n",
    "        int_indexes.append(col_index)\n",
    "    import pandas as pd\n",
    "    # Step 4: Upsample the minority class using ForestDiffusionModel\n",
    "    forest_model = ForestDiffusionModel(X_minority, label_y=y_minority, n_t=50, duplicate_K=100, bin_indexes=[], cat_indexes=[], int_indexes=[], diffusion_type='flow', n_jobs=-1)\n",
    "    Xy_minority_fake = forest_model.generate(batch_size=100 )  # Adjust the batch size to create a balanced dataset\n",
    "    # Add generated samples to the main imbalanced dataset\n",
    "    X_minority_fake = Xy_minority_fake[:, :-1]   # Features\n",
    "    y_minority_fake = Xy_minority_fake[:, -1] # Labels (binary classification)\n",
    "    X_balanced = np.concatenate((X, X_minority_fake), axis=0)\n",
    "    y_balanced = np.concatenate((y, y_minority_fake), axis=0)\n",
    "\n",
    "    # # Step 5: Plot the generated data (first two features for visualization)\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.scatter(X_balanced[:, 0], X_balanced[:, 1], c=y_balanced, cmap='viridis', label='Generated Data', s=1)\n",
    "    # plt.title('Data After Generation')\n",
    "    # plt.xlabel('Feature 1')\n",
    "    # plt.ylabel('Feature 2')\n",
    "    # plt.show()\n",
    "\n",
    "    # Check and print the class distribution after augmentation\n",
    "    unique_bal, counts_bal = np.unique(y_balanced, return_counts=True)\n",
    "    class_dist_after = dict(zip(unique_bal, counts_bal))\n",
    "    print(f\"Class distribution after augmentation: {class_dist_after}\")\n",
    "\n",
    "    # Step 6: Split the dataset into training and test sets (original and balanced)\n",
    "    X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_balanced, y_balanced, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Step 7: Train a simple classifier on both original and generated datasets\n",
    "    clf_orig = RandomForestClassifier(random_state=42)\n",
    "    clf_orig.fit(X_train_orig, y_train_orig)\n",
    "\n",
    "    clf_bal = RandomForestClassifier(random_state=42)\n",
    "    clf_bal.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "    # Step 8: Predict and calculate recall and F1 scores\n",
    "    y_pred_orig = clf_orig.predict(X_test_orig)\n",
    "    y_pred_bal = clf_bal.predict(X_test_orig)\n",
    "\n",
    "    prec_orig = precision_score(y_test_orig, y_pred_orig)\n",
    "    prec_bal = precision_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "\n",
    "    recall_orig = recall_score(y_test_orig, y_pred_orig)\n",
    "    recalls_bal = recall_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "    f1_orig = f1_score(y_test_orig, y_pred_orig)\n",
    "    f1_bal = f1_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "    # Step 9: Print the performance metrics\n",
    "    \n",
    "    print(f\"Precision score (original data): {prec_orig:.4f}\")\n",
    "    print(f\"Precision score (generated data): {prec_bal:.4f}\")\n",
    "    print(f\"Recall score (original data): {recall_orig:.4f}\")\n",
    "    print(f\"Recall score (generated data): {recalls_bal:.4f}\")\n",
    "    print(f\"F1 score (original data): {f1_orig:.4f}\")\n",
    "    print(f\"F1 score (generated data): {f1_bal:.4f}\")\n",
    "    print(\"Classification Report (original data):\\n\", classification_report(y_test_orig, y_pred_orig))\n",
    "    print(\"Classification Report (generated data):\\n\", classification_report(y_test_orig, y_pred_bal))\n",
    "\n",
    "    # Step 10: Print the number of fake samples generated\n",
    "    print(f\"Number of fake samples generated: {len(X_minority_fake)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
