{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3499407209.py, line 84)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 84\u001b[1;36m\u001b[0m\n\u001b[1;33m    int_indexes.append(col_index)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ForestDiffusion import ForestDiffusionModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Step 1: Load your dataset (assuming X is the feature matrix and y is the target variable)\n",
    "# Replace this with your data loading method\n",
    "dataset='diabetes'\n",
    "file_path = f'..\\\\..\\\\..\\\\Datasets\\\\Original Data\\\\{dataset}.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Inspect the data and check for class imbalance\n",
    "# Assuming the last column is the label, and the rest are features\n",
    "X = data.iloc[:, :-1].values  # Features\n",
    "y = data.iloc[:, -1].values  # Labels (binary classification)\n",
    "\n",
    "# Check and print the original class distribution\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "class_dist_before = dict(zip(unique, counts))\n",
    "print(f\"Class distribution before augmentation: {class_dist_before}\")\n",
    "\n",
    "# Step 3: Plot the original imbalanced data (first two features for visualization)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', label='Original Data', s=1)\n",
    "plt.title('Original Imbalanced Data')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()\n",
    "# Separate the minority class\n",
    "X_minority = X[y == 1]\n",
    "\n",
    "# Step 2: Feature selection based on strongest correlation with the target\n",
    "# Using SelectKBest to select top features correlated with target\n",
    "selector = SelectKBest(score_func=f_classif, k=5)  # Adjust k based on the number of features to select\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Get selected feature indices and names\n",
    "selected_features = selector.get_support(indices=True)\n",
    "\n",
    "# Step 3: Calculate the correlation matrix for the selected features of the minority class\n",
    "X_selected_minority = X_minority[:, selected_features]\n",
    "correlation_matrix = pd.DataFrame(X_selected_minority).corr()\n",
    "print(\"Correlation Matrix of Selected Features:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Function to make the correlation matrix positive definite if necessary\n",
    "def make_positive_definite(matrix, epsilon=1e-5):\n",
    "    \"\"\"\n",
    "    Adjusts the matrix to be positive definite by adding epsilon to the diagonal elements.\n",
    "    \n",
    "    Args:\n",
    "        matrix (numpy.ndarray): The correlation matrix.\n",
    "        epsilon (float): Small value to add to the diagonal to ensure positive definiteness.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Positive definite matrix.\n",
    "    \"\"\"\n",
    "    # Check if the matrix is positive definite\n",
    "    eigenvalues = np.linalg.eigvalsh(matrix)\n",
    "    if np.all(eigenvalues > 0):\n",
    "        return matrix\n",
    "    \n",
    "    # Add epsilon to the diagonal if not positive definite\n",
    "    print(\"Adjusting matrix to be positive definite.\")\n",
    "    adjusted_matrix = matrix + np.eye(matrix.shape[0]) * epsilon\n",
    "    \n",
    "    # Re-check to confirm positive definiteness\n",
    "    eigenvalues = np.linalg.eigvalsh(adjusted_matrix)\n",
    "    assert np.all(eigenvalues > 0), \"Failed to make the matrix positive definite.\"\n",
    "    return adjusted_matrix\n",
    "\n",
    "# Step 4: Ensure the correlation matrix is positive definite\n",
    "positive_definite_corr_matrix = make_positive_definite(correlation_matrix.values)\n",
    "\n",
    "# Step 5: Upsample the minority class using ForestDiffusionModel\n",
    "int_columns = data.select_dtypes(include=['int']).columns\n",
    "int_indexes = []\n",
    "for col in int_columns:\n",
    "    col_index = data.columns.get_loc(col)\n",
    "        int_indexes.append(col_index)\n",
    "\n",
    "# Assuming you have defined ForestDiffusionModel previously\n",
    "forest_model = ForestDiffusionModel(X_minority, label_y=None, n_t=50, duplicate_K=100, \n",
    "                                    bin_indexes=[], cat_indexes=[], int_indexes=int_indexes, \n",
    "                                    diffusion_type='flow', n_jobs=-1)\n",
    "\n",
    "X_minority_fake = forest_model.generate(batch_size=len(X) // 50)\n",
    "\n",
    "# Function to adjust the correlations of the selected features in the generated data\n",
    "def adjust_selected_correlation(X, target_corr_matrix, selected_features):\n",
    "    \"\"\"\n",
    "    Adjusts the correlations of selected features in X to match the target correlation matrix.\n",
    "    \n",
    "    Args:\n",
    "        X (numpy.ndarray): The dataset whose selected features' correlations need adjusting.\n",
    "        target_corr_matrix (numpy.ndarray): The target correlation matrix for selected features.\n",
    "        selected_features (list): List of indices for the selected features.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Dataset with adjusted correlations for the selected features.\n",
    "    \"\"\"\n",
    "    # Extract only the selected features from X\n",
    "    X_selected = X[:, selected_features]\n",
    "    \n",
    "    # Calculate the Cholesky decomposition of the target correlation matrix\n",
    "    L = np.linalg.cholesky(target_corr_matrix)\n",
    "    \n",
    "    # Center the data for selected features\n",
    "    X_selected_centered = X_selected - np.mean(X_selected, axis=0)\n",
    "    \n",
    "    # Transform the selected features to match the target correlation structure\n",
    "    X_selected_transformed = np.dot(X_selected_centered, L.T) + np.mean(X_selected, axis=0)\n",
    "    \n",
    "    # Replace the selected features in the original dataset with the transformed features\n",
    "    X_adjusted = X.copy()\n",
    "    X_adjusted[:, selected_features] = X_selected_transformed\n",
    "    \n",
    "    return X_adjusted\n",
    "\n",
    "# Step 6: Adjust the synthetic data to match the correlation structure of selected features\n",
    "X_minority_fake_adjusted = adjust_selected_correlation(X_minority_fake, positive_definite_corr_matrix, selected_features)\n",
    "\n",
    "# Step 7: Add the generated samples to the main imbalanced dataset\n",
    "X_balanced = np.concatenate((X, X_minority_fake_adjusted), axis=0)\n",
    "y_balanced = np.concatenate((y, np.ones(X_minority_fake_adjusted.shape[0])), axis=0)\n",
    "\n",
    "# Check and print the class distribution after augmentation\n",
    "unique_bal, counts_bal = np.unique(y_balanced, return_counts=True)\n",
    "class_dist_after = dict(zip(unique_bal, counts_bal))\n",
    "print(f\"Class distribution after augmentation: {class_dist_after}\")\n",
    "\n",
    "# Step 8: Split the dataset into training and test sets (original and balanced)\n",
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_balanced, y_balanced, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 9: Train a simple classifier on both original and generated datasets\n",
    "clf_orig = RandomForestClassifier(random_state=42)\n",
    "clf_orig.fit(X_train_orig, y_train_orig)\n",
    "\n",
    "clf_bal = RandomForestClassifier(random_state=42)\n",
    "clf_bal.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Step 10: Predict and calculate recall and F1 scores\n",
    "y_pred_orig = clf_orig.predict(X_test_orig)\n",
    "y_pred_bal = clf_bal.predict(X_test_orig)\n",
    "\n",
    "recall_orig = recall_score(y_test_orig, y_pred_orig)\n",
    "recall_bal = recall_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "f1_orig = f1_score(y_test_orig, y_pred_orig)\n",
    "f1_bal = f1_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "# Step 11: Print the performance metrics\n",
    "print(f\"Recall score (original data): {recall_orig:.4f}\")\n",
    "print(f\"Recall score (generated data): {recall_bal:.4f}\")\n",
    "print(f\"F1 score (original data): {f1_orig:.4f}\")\n",
    "print(f\"F1 score (generated data): {f1_bal:.4f}\")\n",
    "\n",
    "print(\"Classification Report (original data):\\n\", classification_report(y_test_orig, y_pred_orig))\n",
    "print(\"Classification Report (generated data):\\n\", classification_report(y_test_orig, y_pred_bal))\n",
    "\n",
    "# Step 12: Print the number of fake samples generated\n",
    "print(f\"Number of fake samples generated: {len(X_minority_fake_adjusted)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before augmentation: {-1: 9236, 1: 586}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAHWCAYAAADaeuaGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+fElEQVR4nO3deVhUZf8G8HuGnQEGUBFQVBQLV1xQc8vXFU1FzayMFJc0EzO1XFrE1AytX0ZqrvW6p6m5llpmrmW54pKJGyrilhsjO8w8vz94GR0PgwwMPqPcn+ua65o537N855lh7jlzDjMqIYQAERGRRGrZDRARETGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMyKo+/vhjqFSqIi27aNEiqFQqXLhwwbpNPeDChQtQqVRYtGhRiW3DnJ07d0KlUmHNmjVWW2dxxtvWqFQqfPzxx7LbIEkYRgQA+Pvvv/H666+jQoUKcHJygr+/PyIiIvD333/Lbk2KkggOKr68NxN5FwcHB5QtWxbNmjXDBx98gEuXLhV53VeuXMHHH3+MuLg46zVMhcYwIqxduxYNGjTA9u3b0b9/f8yePRsDBw7Ejh070KBBA6xbt67Q6/roo4+Qnp5epD769OmD9PR0VK5cuUjLU+nRu3dvLF26FN9++y3Gjx+PqlWrIjY2FjVq1MDKlSuLtM4rV65g4sSJDCNJ7GU3QHKdO3cOffr0QdWqVbF7926UK1fOWHvnnXfQsmVL9OnTB8eOHUPVqlXNric1NRUajQb29vawty/a08rOzg52dnZFWpZKlwYNGuD11183mXbx4kV06NABkZGRqFGjBkJCQiR1R0XBPaNS7vPPP0daWhrmz59vEkQAULZsWcybNw+pqan47LPPjNPzjlOcPHkSr732Gry8vNCiRQuT2oPS09MxfPhwlC1bFu7u7ggPD0dSUpLiGEF+x4yqVKmCLl26YO/evWjcuDGcnZ1RtWpVLFmyxGQbt2/fxnvvvYc6derAzc0NHh4e6NSpE44ePWqlkbp/306fPo3XX38dWq0W5cqVw/jx4yGEQGJiIrp16wYPDw/4+vriiy++yHc9er0eH3zwAXx9faHRaBAeHo7ExESTefbs2YNevXqhUqVKcHJyQkBAAEaOHFmovc6FCxeiTZs28PHxgZOTE2rWrIk5c+Yo5ivs2ALA3bt3MXLkSFSpUgVOTk6oWLEi+vbti5s3bxrnyczMxIQJExAUFGTsecyYMcjMzDRZV2ZmJkaOHIly5coZnw+XL19+5P16lMqVK2PRokXIysoyeb4W5rmxc+dONGrUCADQv39/48eAeccWi/N4UOFwz6iU27RpE6pUqYKWLVvmW3/++edRpUoV/PTTT4par169UL16dXz66aco6JdI+vXrh1WrVqFPnz547rnnsGvXLnTu3LnQPZ49exYvvfQSBg4ciMjISPz3v/9Fv3790LBhQ9SqVQsAcP78eaxfvx69evVCYGAgrl+/jnnz5qFVq1Y4efIk/P39C729R3nllVdQo0YNTJ06FT/99BM++eQTeHt7Y968eWjTpg2mTZuG5cuX47333kOjRo3w/PPPmyw/ZcoUqFQqjB07Fjdu3EBsbCzatWuHuLg4uLi4AABWr16NtLQ0vPXWWyhTpgz279+PmTNn4vLly1i9enWB/c2ZMwe1atVCeHg47O3tsWnTJgwdOhQGgwFRUVEWj21KSgpatmyJf/75BwMGDECDBg1w8+ZNbNy4EZcvX0bZsmVhMBgQHh6OvXv3YvDgwahRowaOHz+OL7/8EqdPn8b69euN23zjjTewbNkyvPbaa2jWrBl+++03i54PBWnatCmqVauGbdu2GacV5rlRo0YNTJo0CdHR0Rg8eLDx76FZs2YAivd4UCEJKrXu3r0rAIhu3boVOF94eLgAIHQ6nRBCiAkTJggAonfv3op582p5Dh06JACIESNGmMzXr18/AUBMmDDBOG3hwoUCgEhISDBOq1y5sgAgdu/ebZx248YN4eTkJN59913jtIyMDKHX6022kZCQIJycnMSkSZNMpgEQCxcuLPA+79ixQwAQq1evVty3wYMHG6fl5OSIihUrCpVKJaZOnWqcfufOHeHi4iIiIyMV66xQoYJxLIUQYtWqVQKA+Oqrr4zT0tLSFD3FxMQIlUolLl68qOjpQfktGxYWJqpWrWoyrbBjGx0dLQCItWvXKtZrMBiEEEIsXbpUqNVqsWfPHpP63LlzBQDx+++/CyGEiIuLEwDE0KFDTeZ77bXXFM+H/OQ9fp9//rnZebp16yYAiOTkZCFE4Z8bBw4cMPvcKOzjQUXHj+lKsXv37gEA3N3dC5wvr67T6UymDxky5JHb2Lp1KwBg6NChJtPffvvtQvdZs2ZNkz23cuXK4dlnn8X58+eN05ycnKBW5z6d9Xo9bt26BTc3Nzz77LM4fPhwobdVGG+88Ybxup2dHUJDQyGEwMCBA43TPT09FT3m6du3r8mYv/TSS/Dz88PmzZuN0/L2kIDc43E3b95Es2bNIITAkSNHCuzvwWWTk5Nx8+ZNtGrVCufPn0dycrLJvIUZ2x9++AEhISHo0aOHYlt5H8muXr0aNWrUQHBwMG7evGm8tGnTBgCwY8cOADDex+HDh5usZ8SIEQXeJ0u4ubkBuP/8tsZzoziPBxUOP6YrxfJeEPP+aM0xF1qBgYGP3MbFixehVqsV8wYFBRW6z0qVKimmeXl54c6dO8bbBoMBX331FWbPno2EhATo9XpjrUyZMoXeVlH60Wq1cHZ2RtmyZRXTb926pVi+evXqJrdVKhWCgoJMjpVdunQJ0dHR2Lhxo8n9BKAIlIf9/vvvmDBhAvbt24e0tDTFslqt1ux9AZRje+7cOfTs2bPAbZ45cwb//POP4rhjnhs3bgC4/3yoVq2aSf3ZZ58tcP2WSElJAXD/+WqN50ZxHg8qHIZRKabVauHn54djx44VON+xY8dQoUIFeHh4mEx/8N1iSTJ3hp144DjVp59+ivHjx2PAgAGYPHkyvL29oVarMWLECBgMhhLvpzA9FpZer0f79u1x+/ZtjB07FsHBwdBoNEhKSkK/fv0KvD/nzp1D27ZtERwcjOnTpyMgIACOjo7YvHkzvvzyS8Wy1urbYDCgTp06mD59er71gIAAi9ZXHCdOnICPj4/x+Vrc50ZxHg8qPIZRKdelSxcsWLAAe/fuNZ4R96A9e/bgwoULePPNN4u0/sqVK8NgMCAhIcFkj+Ds2bNF7jk/a9asQevWrfHtt9+aTL97965ij0W2M2fOmNwWQuDs2bOoW7cuAOD48eM4ffo0Fi9ejL59+xrne/CgvDmbNm1CZmYmNm7caLLXk/cxWVFUq1YNJ06ceOQ8R48eRdu2bQv8Roi858O5c+dM9obi4+OL3N+D9u3bh3Pnzpmc9l3Y54a5vovzeFDh8ZhRKTd69Gi4uLjgzTffVHykdPv2bQwZMgSurq4YPXp0kdYfFhYGAJg9e7bJ9JkzZxatYTPs7OwU7+ZXr16NpKQkq27HGpYsWWLy0eiaNWtw9epVdOrUCcD9vZUH748QAl999dUj153fssnJyVi4cGGR++3ZsyeOHj2a7z8/523n5ZdfRlJSEhYsWKCYJz09HampqQBgvI8zZswwmSc2NrbI/eW5ePEi+vXrB0dHR5Pna2GfGxqNBkBuSD2oOI8HFR73jEq56tWrY/HixYiIiECdOnUwcOBABAYG4sKFC/j2229x8+ZNrFixQvEZf2E1bNgQPXv2RGxsLG7dumU8tfv06dMAzL8btVSXLl0wadIk9O/fH82aNcPx48exfPnyAv9RVxZvb2+0aNEC/fv3x/Xr1xEbG4ugoCAMGjQIABAcHIxq1arhvffeQ1JSEjw8PPDDDz8ojlXkp0OHDnB0dETXrl3x5ptvIiUlBQsWLICPjw+uXr1apH5Hjx6NNWvWoFevXhgwYAAaNmyI27dvY+PGjZg7dy5CQkLQp08frFq1CkOGDMGOHTvQvHlz6PV6nDp1CqtWrcLPP/+M0NBQ1KtXD71798bs2bORnJyMZs2aYfv27RbvKR8+fBjLli2DwWDA3bt3ceDAAfzwww9QqVRYunSpcS8TKPxzo1q1avD09MTcuXPh7u4OjUaDJk2aFOvxIAtIOIOPbNCxY8dE7969hZ+fn3BwcBC+vr6id+/e4vjx44p5804n/vfff83WHpSamiqioqKEt7e3cHNzE927dxfx8fECgMnp0OZO7e7cubNiO61atRKtWrUy3s7IyBDvvvuu8PPzEy4uLqJ58+Zi3759ivmscWr3w/c7MjJSaDSafHusVauWYp0rVqwQ77//vvDx8REuLi6ic+fOitODT548Kdq1ayfc3NxE2bJlxaBBg8TRo0cVvec33hs3bhR169YVzs7OokqVKmLatGniv//9b5HHVgghbt26JYYNGyYqVKggHB0dRcWKFUVkZKS4efOmcZ6srCwxbdo0UatWLeHk5CS8vLxEw4YNxcSJE42nWQshRHp6uhg+fLgoU6aM0Gg0omvXriIxMdGiU7vzLvb29sLb21s0adJEvP/++/meZl3Y54YQQmzYsEHUrFlT2Nvbm4x1YR8PKjqVEEU4wkpUTHFxcahfvz6WLVuGiIgI2e0QkWQ8ZkQlLr+vTImNjYVarVZ8OwERlU48ZkQl7rPPPsOhQ4fQunVr2NvbY8uWLdiyZQsGDx78WE/5JSLbxY/pqMRt27YNEydOxMmTJ5GSkoJKlSqhT58++PDDD4v8Dd9E9HRhGBERkXQ8ZkRERNIxjIiISLqn/gN7g8GAK1euwN3d3Wr/YElERI8mhMC9e/fg7+9v/OZ0c576MLpy5QrP2CIikigxMREVK1YscJ6nPozyvkY+MTFR8a3TRERUcnQ6HQICAh75m2lAKQijvI/mPDw8GEZERBIU5hAJT2AgIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCSd1DDavXs3unbtCn9/f6hUKqxfv96kLoRAdHQ0/Pz84OLignbt2uHMmTNymiUiohIjNYxSU1MREhKCr7/+Ot/6Z599hhkzZmDu3Ln466+/oNFoEBYWhoyMjMfcKRERlSSpX5TaqVMndOrUKd+aEAKxsbH46KOP0K1bNwDAkiVLUL58eaxfvx6vvvrq42yVKF9J567CkGNAwLMVZLdC9ESz2WNGCQkJuHbtGtq1a2ecptVq0aRJE+zbt8/scpmZmdDpdCYXopLw1+bD6Fd9OAbUGIEd3/8uux2iJ5rNhtG1a9cAAOXLlzeZXr58eWMtPzExMdBqtcYLf1iPSsrff5wyXj+x91QBcxLRo9hsGBXV+++/j+TkZOMlMTFRdkv0lHo9uhdCw0JQr3VtDJoWIbsdoieazf64nq+vLwDg+vXr8PPzM06/fv066tWrZ3Y5JycnODk5lXR7RHB0dEDMlo9kt0H0VLDZPaPAwED4+vpi+/btxmk6nQ5//fUXmjZtKrEzIiKyNql7RikpKTh79qzxdkJCAuLi4uDt7Y1KlSphxIgR+OSTT1C9enUEBgZi/Pjx8Pf3R/fu3eU1TUREVic1jA4ePIjWrVsbb48aNQoAEBkZiUWLFmHMmDFITU3F4MGDcffuXbRo0QJbt26Fs7OzrJaJiKgEqIQQQnYTJUmn00Gr1SI5ORkeHh6y2yEiKjUsef212WNGRERUejCMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJZ9NhpNfrMX78eAQGBsLFxQXVqlXD5MmTIYSQ3RoREVmRvewGCjJt2jTMmTMHixcvRq1atXDw4EH0798fWq0Ww4cPl90eERFZiU2H0R9//IFu3bqhc+fOAIAqVapgxYoV2L9/v+TO6GmxZvomGPQGvDy6m+xWiEo1mw6jZs2aYf78+Th9+jSeeeYZHD16FHv37sX06dPNLpOZmYnMzEzjbZ1O9zhapSfQD7E/Yt57SwAAQgi8Mqa73IaISjGbDqNx48ZBp9MhODgYdnZ20Ov1mDJlCiIiIswuExMTg4kTJz7GLomIqLhsOoxWrVqF5cuX47vvvkOtWrUQFxeHESNGwN/fH5GRkfku8/7772PUqFHG2zqdDgEBAY+rZXqC9BzRBcIg+DEdkQ1QCRs+NS0gIADjxo1DVFSUcdonn3yCZcuW4dSpU4Vah06ng1arRXJyMjw8PEqqVSIieoglr782fWp3Wloa1GrTFu3s7GAwGCR1REREJcGmP6br2rUrpkyZgkqVKqFWrVo4cuQIpk+fjgEDBshujYiIrMimP6a7d+8exo8fj3Xr1uHGjRvw9/dH7969ER0dDUdHx0Ktgx/TERHJYcnrr02HkTUwjIiI5HhqjhkREVHpwDAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRETSdNZEIMzhFdy4dkd2KyQZw4iIpOhbfRiy0rNg0BvQt9IQ2e2QZAwjIpLCN7Cc8bqzxlliJ2QLGEZEJMVnv0xAs/BQBDWogvV3FstuhySzl90AEZVeE9ePld0C2QjuGRERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQWhVF6ejr27t2LkydPKmoZGRlYsmSJ1RojIqLSo9BhdPr0adSoUQPPP/886tSpg1atWuHq1avGenJyMvr3718iTRIR0dOt0GE0duxY1K5dGzdu3EB8fDzc3d3RvHlzXLp0qST7IyKiUqDQYfTHH38gJiYGZcuWRVBQEDZt2oSwsDC0bNkS58+fL8keiYjoKVfoMEpPT4e9vb3xtkqlwpw5c9C1a1e0atUKp0+fLpEGiYjo6Wf/6FlyBQcH4+DBg6hRo4bJ9FmzZgEAwsPDrdsZERGVGoXeM+rRowdWrFiRb23WrFno3bs3hBBWa4yIiEoPlbDxBElKSsLYsWOxZcsWpKWlISgoCAsXLkRoaGihltfpdNBqtUhOToaHh0cJd0tERHksef0t9Md0Mty5cwfNmzdH69atsWXLFpQrVw5nzpyBl5eX7NaIiMiKbDqMpk2bhoCAACxcuNA4LTAwUGJH9Djpc/RYOW091Go1Xh4TDjs7O9ktlSoGgwE/fPkT0nRp6P3Bi3B0crDq+oUQWPfVZuhu3UPvD3rAycXJquunJ4tNh9HGjRsRFhaGXr16YdeuXahQoQKGDh2KQYMGmV0mMzMTmZmZxts6ne5xtEolYO/av7Bo/EoAQECwP1r0aCK5o9IlbsffmD8691tVygWUxQtvtLXq+o/tPok5oxYBAMr4e6HrW2FWXT89WWz6u+nOnz+POXPmoHr16vj555/x1ltvYfjw4Vi8eLHZZWJiYqDVao2XgICAx9gxWVNAcAU4ONrD0dkBAc/6y26n1PGr6gNnjRPs7NWoUqui9dcf6AMXdxeo7dSoUruS1ddPTxabPoHB0dERoaGh+OOPP4zThg8fjgMHDmDfvn35LpPfnlFAQABPYHhC6W7dAwB4lHGX3EnplHI3FdlZOfDy0T6R6ye5LDmBoUh7RkuXLkXz5s3h7++PixcvAgBiY2OxYcOGoqzOLD8/P9SsWdNkWo0aNQr8CiInJyd4eHiYXOjJ5VHGnUEkkZunpkSDoqTXT08Oi8Nozpw5GDVqFF544QXcvXsXer0eAODp6YnY2FirNte8eXPEx8ebTDt9+jQqV65s1e0QEZFcFofRzJkzsWDBAnz44YcmZzeFhobi+PHjVm1u5MiR+PPPP/Hpp5/i7Nmz+O677zB//nxERUVZdTtERCSXxWGUkJCA+vXrK6Y7OTkhNTXVKk3ladSoEdatW4cVK1agdu3amDx5MmJjYxEREWHV7RARkVwWn9odGBiIuLg4xUdlW7duVXxvnTV06dIFXbp0sfp6iYjIdlgcRqNGjUJUVBQyMjIghMD+/fuxYsUKxMTE4JtvvimJHomI6ClncRi98cYbcHFxwUcffYS0tDS89tpr8Pf3x1dffYVXX321JHokIqKnnEVhlJOTg++++w5hYWGIiIhAWloaUlJS4OPjU1L9ERFRKWDRCQz29vYYMmQIMjIyAACurq4MIiIiKjaLz6Zr3Lgxjhw5UhK9EBFRKWXxMaOhQ4fi3XffxeXLl9GwYUNoNBqTet26da3WHBERlQ4WfzedWq3cmVKpVBBCQKVSGb+RwVbwx/WIiOQo0R/XS0hIKHJjRERE+bE4jPi9cEREZG0Wh9GSJUsKrPft27fIzRARUelk8TEjLy8vk9vZ2dlIS0uDo6MjXF1dcfv2bas2WFw8ZkREJEeJ/p7RnTt3TC4pKSmIj49HixYtsGLFiiI3TUREpZdVfna8evXqmDp1Kt555x1rrI6IiEoZq4QRkPvtDFeuXLHW6oiIqBSx+ASGjRs3mtwWQuDq1auYNWsWmjdvbrXGiIio9LA4jLp3725yW6VSoVy5cmjTpg2++OILa/VFRESliMVhZDAYSqIPIiIqxSw+ZjRp0iSkpaUppqenp2PSpElWaYqIiEoXi//PyM7ODlevXlX8dMStW7fg4+PD76YjIiIAJfx/RnlfiPqwo0ePwtvb29LVERERFf6YkZeXF1QqFVQqFZ555hmTQNLr9UhJScGQIUNKpEkiInq6FTqMYmNjIYTAgAEDMHHiRGi1WmPN0dERVapUQdOmTUukSSIieroVOowiIyMBAIGBgWjWrBkcHBxKrCkiIipdLD61u1WrVsbrGRkZyMrKMqnzJAEiIrKUxScwpKWlYdiwYfDx8YFGo4GXl5fJhYiIyFIWh9Ho0aPx22+/Yc6cOXBycsI333yDiRMnwt/f/5G/dURERJQfiz+m27RpE5YsWYL//Oc/6N+/P1q2bImgoCBUrlwZy5cvR0REREn0SURETzGL94xu376NqlWrAsg9PpT3Y3otWrTA7t27rdsdERGVChaHUdWqVZGQkAAACA4OxqpVqwDk7jF5enpatTkiIiodLA6j/v374+jRowCAcePG4euvv4azszNGjhyJ0aNHW71BIiJ6+ln83XQPu3jxIg4dOoSgoCDUrVvXWn1ZDb+bjkpKVkYW5r23BPpsPd6cHgkXjbPslkxkZ2Vj/uilyEjNxFtf9oOru4vslkzoc/RYMHYZ7t1OwVtf9oObp0Z2S2Rllrz+WnwCw4MyMjJQuXJlVK5cuTirIXoi/fXTYWyc/TMAoFbzYLTv2+oRSzxeh7cdw/qZWwAAwY2D0Hlwe8kdmTq66yR++PJHAEBQ/UD0GP6C5I5IJos/ptPr9Zg8eTIqVKgANzc3nD9/HgAwfvx4fPvtt1ZvkMhWPRNaDdpyHnDz0qBG02dkt6NQrX4gvH09odG6olbzYNntKATWqYSyFbzh4uaMOs/XkN0OSWbxx3STJk3C4sWLMWnSJAwaNAgnTpxA1apV8f333yM2Nhb79u0rqV6LhB/TUUnS5+T+ZIqdvZ3kTvKn1+shDAL2DsX6EKTE2Hp/VDwl+hMSS5Yswfz58xEREQE7u/t/gCEhITh16pTl3RI9wezs7Ww2iIDc3x+z5Rd6W++PHh+LwygpKQlBQUGK6QaDAdnZ2VZpioiISheLw6hmzZrYs2ePYvqaNWtQv359qzRFRESli8X7x9HR0YiMjERSUhIMBgPWrl2L+Ph4LFmyBD/++GNJ9EhERE85i/eMunXrhk2bNuHXX3+FRqNBdHQ0/vnnH2zatAnt29vWqaNERPRkKPTZdOfPn0dgYKDJz40/CXg2HRGRHCVyNl316tXx77//Gm+/8soruH79etG7JCIi+p9Ch9HDO1CbN29Gamqq1RsiIqLSx+JjRkRERNZW6DBSqVSK40VP2vEjIiKyTYU+tVsIgX79+sHJyQlA7pekDhkyBBqN6Tftrl271rodEhHRU6/QYRQZGWly+/XXX7d6M0REVDoVOowWLlxYkn0QEVEpxhMYiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCTdExVGU6dOhUqlwogRI2S3QkREVvTEhNGBAwcwb9481K1bV3YrRERkZU9EGKWkpCAiIgILFiyAl5eX7HaIbEJ6Sjqiu0/DmA6TcPffZNntWOzfpFvo7PoawhxewaFtR2W3Q5I9EWEUFRWFzp07o127do+cNzMzEzqdzuRC9DQ6sv0E9m08iCO/Hsfetftlt2OxReNXIisjGwa9AXPfXSy7HZLM5sNo5cqVOHz4MGJiYgo1f0xMDLRarfESEBBQwh0SyVG7RTCC6gei4rP+aNSxnux2LNZrVFeo1Krc6++FS+6GZFMJIYTsJsxJTExEaGgotm3bZjxW9J///Af16tVDbGxsvstkZmYiMzPTeFun0yEgIADJycnw8PB4HG0TERFyX3+1Wm2hXn9tOozWr1+PHj16wM7OzjhNr9dDpVJBrVYjMzPTpJYfSwaDiIisx5LXX/vH1FORtG3bFsePHzeZ1r9/fwQHB2Ps2LGPDCIiInoy2HQYubu7o3bt2ibTNBoNypQpo5hORERPLps/gYGIiJ5+Nr1nlJ+dO3fKboGIiKyMe0ZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoaRRC+W64/26l5or+6FD7pMsfr6r1/8F/2Ch+OthmOgu3XP6uv/9/ItDKj5Dt6s/x7u/pucb31grREYXO9d3LmhrN9MuoWBtUdicEj+9eJaPGGlcXz/+8F3ivrta3cwqO4oDKw9Ejev3LZ4/XduJGNwvXcxsNYI3Ey6ZY2WTSTf1GFIg9HoX+Md3Lj0r6KedOYqOmsi0MnpVfz9+yll/dz9+vG9/1i8/Xt3UjC00Vj0e/ZtXE24rqhPeXUiXnDpiY4OL2FgjdcsXv+KaeuMj09Uk3EWL09PF4aRRPdupRivH9gcZ/X1H9gah6TTV3H2SAJO7FW+WBXXoV+OIvHUFZw/ehHHdp1U1rcdw6V/kpBw7FK+9cO/Hselk5eRcPwSju44YfX+Vk//0Xh97YzNinrcjr9x4UQiLp28jCPbj1u8/mM7/0bCsUu49E8SDm07Vqxe83N8zz84F3cBl+Ov4ODPRxX1nxfuQFZ6FnKy9dg45+cC65tmK+uPcvKPeJw5dB5JZ65h/+Yjivrp/QeRnamGXq9Cdqblb3aWTVp9f10Hzlm8PD1dGEYSVapVwXi99wc9rL7+Fi82Rv12ddA0PBT129a2+vqbdWuEhh3q4rkuDREaVk9ZDw9Fww510aRzA4SGhSjqz3VtiNCwEDTp3ACNOtW3en/DZw24f/3rAYp6kxfqo/EL9RHasR6e69LQ4vWHdqyHJp0boGGHEDQNDy1Wr/lp2L4umnYNRYP2ddG8R2NFvfvwTvAqr4Wbtxte+7Cnot5j+Avw9vWEm5cm3/qjhLSujebdG6Ne69p4/qXnFPU2fXrCTZsDZ40enn4VLV7/uGXDjdf/80ozi5enp4tKCCFkN1GSdDodtFotkpOT4eHhIbsdIqJSw5LXX+4ZERGRdAwjIiKSjmFERETSMYyIiEg6hhEREUnHMCIiIukYRkREJB3DiIiIpGMYERGRdAwjIiKSjmFERETSMYyIiEg6hhEREUnHMCIiIukYRkREJB3DiIiIpGMYERGRdAwjIiKSjmFERETSMYyIiEg6hhEREUnHMCIiIukYRkREJB3DiIiIpGMYERGRdAwjIiKSjmFERETSMYyIiEg6hhEREUnHMCIiIukYRkREJB3DiIiIpLPpMIqJiUGjRo3g7u4OHx8fdO/eHfHx8bLbIiIiK7PpMNq1axeioqLw559/Ytu2bcjOzkaHDh2QmpoquzUiIrIimw6jrVu3ol+/fqhVqxZCQkKwaNEiXLp0CYcOHXpsPaQkpyA9PdNsPSMtA1lZ2Wbrh7b/gfPHT5ut//b9bzjxx0mz9WuXruP27Xtm61P7f4ol/7fcbP3CqQTcuHrTbP3LYZOwYPIss/V9Ww7gxD7ze6P7f9mN/b/sNltfNmkBlk1aYLa+9ds52PrtnAK2/zv2bfndbL24Uu6mIOVuSpGXT76ZjOSbyVbsyNTlhOtIOJFgtr510U/4Zrz58d29Zh+Wf/6D2fqxvf9g23c7zNZv3riNy2cTzdazsrKRkZZhtr7xmy34+t1vzdavJd3C2eMXzNYf5XLCFZzcb/7vR6/XIyc7x/z2L13G2WMnzNbbq3uhvbqX2frqGZvwbqcJZusGgwHZBbw+PMrN61dwYt9+s/XExEvYs/EPs/Wv352JiCDz/dsSlRBCyG6isM6ePYvq1avj+PHjqF27dr7zZGZmIjPzfnjodDoEBAQgOTkZHh4eFm1v5bR1+Pb97wAAX+6ZjNrNg03qu1b9gU9e/RJqtQrzjn6BKrUCTOoRlXvhRmLu8Dbp5I9PfpphUu/o2Av6nNy6X1AZLDk9z6Q+4cVp+GP9QQDAwE9fw6vjepjUu2i6IzPdHgDg4p6Bjck/mtTHdx2OP3+6ApUK6D7sOQz96j2Teg/vcKTcdQQAaMtkYM2/pst3cumNnMzcP2StjzvWXPuvSX1og3CciXOESgXUfE6F2N9Xm9TDPbohPcUBAODmmYl1tzeZ1Cd3b4PdG70BAK263cRH63aa1IeEdMe547n3L6ieCnMOm66/uNbN/Amz31kEABj8eR/0ejfcouWXT/kBi8avBAD0fLcLhnweadX+xrT/GEe2/w0A8KtWDkvOzDapv1imO+7dyR0fd89srL29waT+gmtvZGfcfyHeZjAdv1crDcaty3cAACo7FX7JXmVSXzZ5ARZP+BkA8Fznypi86QuT+vljFzCkwRgIg8D4VaPw/EtNTeodHHtBPJADD29/5jvfYuPMrQAA/+q+WBw/08xI5O/rt6dj95pdSLtnh8Cajpixf6VJXXfrHoY0GI17d1LxxY6P8UzDaib1lTEz8O2HuW+kajRWYcafpv09HEIP9/+oesrdVLzVcAzuXL+Lz36dgJrPPWPR/dswcy4ahs5CGd9szBhXDWO/32xSn/XOXGyY+SsAQG2vxs9Zpo9fJ/cuyEl1zq3b6fFz9jqLtm8NOp0OWq22UK+/Nr1n9CCDwYARI0agefPmZoMIyD3OpNVqjZeAgACz8z7KjhX335FvW7JTUd+1et//ehP46yfl3trNJAMAFQAVju29rKjnBlFu/erZ24r6oV+OGa//OP9XRT0rw864fFa6o6KeeOoCABWEUCFu+5+Kem5Q5C6fnqJcPi+IACD5hnLvLDPNYFx/6p005fpT7Y3rT9M5KOpJ552N9euJLop6RlqOsZ6ZYv7dd1Ft/e/9PYKfF5rfOzDn54W/Ga/vWL7XKj096OiO++/4r577V1HPfRuZOz452co/5QeDKD95QQQAQq98T7pjxQ7j+uMPXFDU9/14CMKQu1ze34JJfwVvHr8uvr9HfeXMtYJnzsfJP3bj9nVHZKTZwd5euXeacOIS/k28hYyUDBzbpdx72rnq/v27dOoRzRbBpVNJuJZwA5lpWTi642+Ll/9n74/wD8yCk4uAfxWdor55wU7k9W/IUT5+IvP+359Bb/sv9bbf4f9ERUXhxIkTWLlyZYHzvf/++0hOTjZeEhPNf8TwKGOXDoOLmzM8y2sx5Avlu943/68P/KuVR/UGVdFj+AuKenhUKAABQGDC2vcU9Uad6xjr7694S1H/cOWo3Csq4P92Rivqnn5q4/KNu9RU1PtOfhueZbNRxjcLY5Z/qqiXC8gxLh/S3l9Rb9+v5f37Or2vot4kvCW8fHLX3/nt3op6UH1v4/obdgxU1Ks18IKrew40Hjmo00r5rrHFiy/A1U0PV/ccdHjD+h81RK9+F/ZO9rB3tEf0D8rH51E++ekDqNVqqNQqTNowxur9Tf5xnPH60Bn9FPXWr7eGnb0BKrWAb7Wyinqv9+/v6VULVY7/mGVDjdcbd6mvqE/cOA3OGj0cnAyImjlUUe85ojOC6gfCP8gXb37eR1GPnPSS8bqbl6uiPvvg/efk4M8jFPVHeX/NbNRpmoKajVJQu00PRb12i2C8/F442vdthQ79/qOof7xhJhyd9VCrDXj5vZaK+qMMjlX+TTwouHEQXh3XA+1efx6d3mhj8frfmDEfq2aXw/YftMhStVLU58V/Zrxep1WQot717bbI+/tzcE63ePuP2xPxMd2wYcOwYcMG7N69G4GByj+qgliym0hERNZjyeuv/WPqqUiEEHj77bexbt067Ny50+IgIiKiJ4NNh1FUVBS+++47bNiwAe7u7rh2LfdzZa1WCxcX5TEGIiJ6Mtn0x3QqlSrf6QsXLkS/fv0KtQ5+TEdEJMdT9TEdERE9/Z6Ys+mIiOjpxTAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5hRERE0jGMiIhIOoYRERFJxzAiIiLpGEZERCQdw4iIiKRjGBERkXQMIyIiko5h9AjdvF5AD68OZusvl++IF8uYr79UrgO6e7YtoN4d3cu8aLbeXt0T7dW9zG/ftxN6+ZrffnevLuju1cN83bsTunmaXz7cvRPC3cPM1ru4FVxvr+6E9mrz9RfLdcSLZc1vP8ypI8KcOpqtF9fwFh9geIsPzNanRs7ExF7/Z7Y+8j/jEdVknNn6xjlbsebLTWbrXT16obPG/OP7QZcpGPac+fV31nRHF01Xs/X26o5or+5ktt7Dqz1eKmD8e5brhFd9zY9/e3WvAp+f3b1eRUdn8/XVX6zHzHe+NVvvXaEd+gWZ76+9ugvaq18wW+/q3g49vAvqv0OBy3d2bYtwbecClm+L9upi1O3aor2d+XpX9zbooilo/W0KXH+YSxt0di1o+YIfvx5l2uBlP/PLW5NKCCEey5Yk0el00Gq1SE5OhoeHh0XLhjn0gEFvBwBwcc/ExmTTF5VX/cNx65ojAKCMXypWJm0xqb/TJAyf/5CArAw13mxdBcsTt5rWG4fh87UJyM5U4802z2DZxY0m9fbqHgDs/ncrC9sMpvWXyoUj+Vbu9r190vH9tZ9M6q9X7ozriS659fJp+P7qZpP6K35dcfu6EwDAs2wGVt/40aT+YpmuuHcnt+7mmYF1t03r7dXdAdgDAFR22fgle4PZOpCNbQbTekRAF9xIcgYAlPVPx4rLP5lfXpWNbXrT5Yurk/OryMnSAwDs7NXYmvW9Sb2X7wDcvXEPAODq6YoNtxeb1F/QvIbs9GwAgNpejZ8fWv6j7jH4a+NhAEBwk+qYue9Tk3p7dTcADv+7lYNthvUm9XDPvkjXpQMAVHYq/JK9yqTe1T0cGam5j7+zaw42pZgu314dDsDxf7f02GZYZ1LvU6Uj5m5PgIOjwLs9AjHz4M8m9dcCXsC/Sa4AAN/KGVia8PDj3wtA3suHCtsMqx+qv4j773eV25/w4jT8sf4gAMCjjBt++HehSX1QzTB8ueEinFwM+PD1Kvhs5y8Prb8LAGez6+9ZthN0tzUAAP8qGVh8/uH+H1zegG2GtSb1btrOSLuX+/fj7pmNtbcffn53BuBidvnckHM1X7d7ARDm613dOiEjTVPA+jsBMF/v7NoRWRluAACVyoBf9A8vbxpCDz9+vcqH4e6/7gAA7/JZ+P6q6etPYVjy+mtfYLWUM+jVAFQAgMw05VCl6uyNdYPeQVGv/EwW7O0BezcD/CobzNftDfCrnJFPB/e3n99DlZ5qZ6xnZyq3b2d/f3lnF+VO8IP3T61W1vXZ9+9f/k+V+9sXersC6/dD9T57R5Wx7uikUtRNlhf5rb948oIIAPQ5yscnL4gAIO1umqKeF0QAYMhn+ZO/nzZeTzh+KZ8OCh6fvCACAKFXvmfU5zzw+GflNz4PPn7Kx9e/igEumtz1Vn42S1F3cHjg+aHK7/HBA+tX3n/TunL7x3efMl6/dztFUfcqJ+DqnrveilWV/eUGufn1u7rZQXf7f89PkV//Dy6vrNvb3x/frMz8xtexwOUfWRcF17MynR6x/oLrBr2zcXr+979g9vb3xycz3fp/fw/jx3QFcC5zBbnv/AwwtMjnxcCQDjt7Axyd9ajWr4qi/uuadCz/0gfzPvbF0T+UD+bfx57Bsuk+mD/RF81eH66olw/0Mm4/ctLLirqr9g7UdgL2DgZo6irX7+ZTGT4VM+FbKQOd3uqjqCffPguNRw7cPHNw+8Z5RT0tNRUOTno4OuuRcjdbUQdSkPsiZACQnk8964G68sXq6lU1ygdkonylTNwyOCrqj15/8UzZOi7f63kW/BNrvP75zgmK+ld/3t/T+WjNCEV9/slYqNQqqNQqzD36maI+aMaryLt/LwxuqajPOzvNeH3M0mGKun9TH6jUBqhUBuhzFGXk/nkbkPscUr6YH9njgQWTfLH0Cx/89oObol425Fn4VsqAT8VMXE9SvlRM3DPCuH7vCp6K+syTU4z12i2rKerLE2cbr0/95SNF3bFFCOZE+2H5lz7YvtZFUXfvbv/A/VM+v65dsoNf5QyUq5CJm9eUbybwrN0DyyvfDOrunIKzix72Dgbk5NxULm8yvnfyqeOB+q18ahkF1g0hKmPd1S2/5W8VuP0tmeuNdTuXu4r6w3tCD1uR9CO0ZbLh4pYDtZ2uwHmtgR/TERFRibDk9Zd7RkREJB3DiIiIpGMYERGRdAwjIiKSjmFERETSMYyIiEg6hhEREUnHMCIiIukYRkREJB3DiIiIpGMYERGRdAwjIiKSjmFERETSMYyIiEi6p/7H9fJ+IUOnK/nf4yAiovvyXncL80tFT30Y3buX+2udAQEBkjshIiqd7t27B61WW+A8T/2P6xkMBly5cgXu7u5Q5fPTyTqdDgEBAUhMTOSP7xUBx694OH7Fw/ErnpIePyEE7t27B39/f6jVBR8Veur3jNRqNSpWrPjI+Tw8PPhkLgaOX/Fw/IqH41c8JTl+j9ojysMTGIiISDqGERERSVfqw8jJyQkTJkyAk5OT7FaeSBy/4uH4FQ/Hr3hsafye+hMYiIjI9pX6PSMiIpKPYURERNIxjIiISDqGERERSVeqw+jrr79GlSpV4OzsjCZNmmD//v2yW7JZu3fvRteuXeHv7w+VSoX169eb1IUQiI6Ohp+fH1xcXNCuXTucOXNGTrM2JiYmBo0aNYK7uzt8fHzQvXt3xMfHm8yTkZGBqKgolClTBm5ubujZsyeuX78uqWPbMmfOHNStW9f4j5lNmzbFli1bjHWOnWWmTp0KlUqFESNGGKfZwhiW2jD6/vvvMWrUKEyYMAGHDx9GSEgIwsLCcOPGDdmt2aTU1FSEhITg66+/zrf+2WefYcaMGZg7dy7++usvaDQahIWFISMj4zF3ant27dqFqKgo/Pnnn9i2bRuys7PRoUMHpKamGucZOXIkNm3ahNWrV2PXrl24cuUKXnzxRYld246KFSti6tSpOHToEA4ePIg2bdqgW7du+PvvvwFw7Cxx4MABzJs3D3Xr1jWZbhNjKEqpxo0bi6ioKONtvV4v/P39RUxMjMSungwAxLp164y3DQaD8PX1FZ9//rlx2t27d4WTk5NYsWKFhA5t240bNwQAsWvXLiFE7lg5ODiI1atXG+f5559/BACxb98+WW3aNC8vL/HNN99w7Cxw7949Ub16dbFt2zbRqlUr8c477wghbOf5Vyr3jLKysnDo0CG0a9fOOE2tVqNdu3bYt2+fxM6eTAkJCbh27ZrJeGq1WjRp0oTjmY/k5GQAgLe3NwDg0KFDyM7ONhm/4OBgVKpUieP3EL1ej5UrVyI1NRVNmzbl2FkgKioKnTt3NhkrwHaef0/9F6Xm5+bNm9Dr9ShfvrzJ9PLly+PUqVOSunpyXbt2DQDyHc+8GuUyGAwYMWIEmjdvjtq1awPIHT9HR0d4enqazMvxu+/48eNo2rQpMjIy4ObmhnXr1qFmzZqIi4vj2BXCypUrcfjwYRw4cEBRs5XnX6kMIyJZoqKicOLECezdu1d2K0+UZ599FnFxcUhOTsaaNWsQGRmJXbt2yW7riZCYmIh33nkH27Ztg7Ozs+x2zCqVH9OVLVsWdnZ2irNFrl+/Dl9fX0ldPbnyxozjWbBhw4bhxx9/xI4dO0x+1sTX1xdZWVm4e/euyfwcv/scHR0RFBSEhg0bIiYmBiEhIfjqq684doVw6NAh3LhxAw0aNIC9vT3s7e2xa9cuzJgxA/b29ihfvrxNjGGpDCNHR0c0bNgQ27dvN04zGAzYvn07mjZtKrGzJ1NgYCB8fX1NxlOn0+Gvv/7ieCL3tPdhw4Zh3bp1+O233xAYGGhSb9iwIRwcHEzGLz4+HpcuXeL4mWEwGJCZmcmxK4S2bdvi+PHjiIuLM15CQ0MRERFhvG4TY/jYTpWwMStXrhROTk5i0aJF4uTJk2Lw4MHC09NTXLt2TXZrNunevXviyJEj4siRIwKAmD59ujhy5Ii4ePGiEEKIqVOnCk9PT7FhwwZx7Ngx0a1bNxEYGCjS09Mldy7fW2+9JbRardi5c6e4evWq8ZKWlmacZ8iQIaJSpUrit99+EwcPHhRNmzYVTZs2ldi17Rg3bpzYtWuXSEhIEMeOHRPjxo0TKpVK/PLLL0IIjl1RPHg2nRC2MYalNoyEEGLmzJmiUqVKwtHRUTRu3Fj8+eefsluyWTt27BAAFJfIyEghRO7p3ePHjxfly5cXTk5Oom3btiI+Pl5u0zYiv3EDIBYuXGicJz09XQwdOlR4eXkJV1dX0aNHD3H16lV5TduQAQMGiMqVKwtHR0dRrlw50bZtW2MQCcGxK4qHw8gWxpA/IUFERNKVymNGRERkWxhGREQkHcOIiIikYxgREZF0DCMiIpKOYURERNIxjIiISDqGERERSccwIiIi6RhGRI/Qr18/qFQqxeXs2bNWWf+iRYsUvyXzuO3evRtdu3aFv78/VCoV1q9fL7UfKn0YRkSF0LFjR1y9etXk8vC3b9uC7OzsIi2XmpqKkJAQfP3111buiKhwGEZEheDk5ARfX1+Ti52dHQBgw4YNaNCgAZydnVG1alVMnDgROTk5xmWnT5+OOnXqQKPRICAgAEOHDkVKSgoAYOfOnejfvz+Sk5ONe1wff/wxAOS7h+Lp6YlFixYBAC5cuACVSoXvv/8erVq1grOzM5YvXw4A+Oabb1CjRg04OzsjODgYs2fPLvD+derUCZ988gl69OhhhdEishx/6ZWoGPbs2YO+fftixowZaNmyJc6dO4fBgwcDACZMmAAAUKvVmDFjBgIDA3H+/HkMHToUY8aMwezZs9GsWTPExsYiOjoa8fHxAAA3NzeLehg3bhy++OIL1K9f3xhI0dHRmDVrFurXr48jR45g0KBB0Gg0iIyMtO4AEFnLY/2OcKInUGRkpLCzsxMajcZ4eemll4QQQrRt21Z8+umnJvMvXbpU+Pn5mV3f6tWrRZkyZYy3Fy5cKLRarWI+AGLdunUm07RarfGnJxISEgQAERsbazJPtWrVxHfffWcybfLkyYX+fZr8tktU0rhnRFQIrVu3xpw5c4y3NRoNAODo0aP4/fffMWXKFGNNr9cjIyMDaWlpcHV1xa+//oqYmBicOnUKOp0OOTk5JvXiCg0NNV5PTU3FuXPnMHDgQAwaNMg4PScnB1qtttjbIiopDCOiQtBoNAgKClJMT0lJwcSJE/Hiiy8qas7Ozrhw4QK6dOmCt956C1OmTIG3tzf27t2LgQMHIisrq8AwUqlUEA/93Fh+JyjkBWNePwCwYMECNGnSxGS+vGNcRLaIYURUDA0aNEB8fHy+QQUAhw4dgsFgwBdffAG1Ovd8oVWrVpnM4+joCL1er1i2XLlyuHr1qvH2mTNnkJaWVmA/5cuXh7+/P86fP4+IiAhL7w6RNAwjomKIjo5Gly5dUKlSJbz00ktQq9U4evQoTpw4gU8++QRBQUHIzs7GzJkz0bVrV/z++++YO3euyTqqVKmClJQUbN++HSEhIXB1dYWrqyvatGmDWbNmoWnTptDr9Rg7diwcHBwe2dPEiRMxfPhwaLVadOzYEZmZmTh48CDu3LmDUaNG5btMSkqKyf9NJSQkIC4uDt7e3qhUqVLxBomoMGQftCKydZGRkaJbt25m61u3bhXNmjUTLi4uwsPDQzRu3FjMnz/fWJ8+fbrw8/MTLi4uIiwsTCxZskQAEHfu3DHOM2TIEFGmTBkBQEyYMEEIIURSUpLo0KGD0Gg0onr16mLz5s35nsBw5MgRRU/Lly8X9erVE46OjsLLy0s8//zzYu3atWbvw44dOwQAxSUyMtKCkSIqOpUQD30oTURE9Jjxn16JiEg6hhEREUnHMCIiIukYRkREJB3DiIiIpGMYERGRdAwjIiKSjmFERETSMYyIiEg6hhEREUnHMCIiIun+HyEvklzWx8L+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 44\u001b[0m\n\u001b[0;32m     35\u001b[0m X_minority \u001b[38;5;241m=\u001b[39m X[y \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# # Identify integer columns\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# int_columns = data.select_dtypes(include=['int']).columns\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# int_indexes = []\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#         int_indexes.append(col_index)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Step 4: Upsample the minority class using ForestDiffusionModel\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m forest_model \u001b[38;5;241m=\u001b[39m \u001b[43mForestDiffusionModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_minority\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduplicate_K\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbin_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mint_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiffusion_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mflow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m X_minority_fake \u001b[38;5;241m=\u001b[39m forest_model\u001b[38;5;241m.\u001b[39mgenerate(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(X)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m50\u001b[39m )  \u001b[38;5;66;03m# Adjust the batch size to create a balanced dataset\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Add generated samples to the main imbalanced dataset\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tawfique\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ForestDiffusion\\diffusion_with_trees_class.py:185\u001b[0m, in \u001b[0;36mForestDiffusionModel.__init__\u001b[1;34m(self, X, X_covs, label_y, n_t, model, diffusion_type, max_depth, n_estimators, eta, tree_method, reg_alpha, reg_lambda, subsample, num_leaves, duplicate_K, bin_indexes, cat_indexes, int_indexes, remove_miss, p_in_one, true_min_max_values, gpu_hist, n_z, eps, beta_min, beta_max, n_jobs, n_batch, seed, **xgboost_kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_batch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m# Data iterator, no need to duplicate, not make xt yet\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregr \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX1_splitted\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_covs_splitted\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_levels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_uniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregr \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)( \u001b[38;5;66;03m# using all cpus\u001b[39;00m\n\u001b[0;32m    188\u001b[0m             delayed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_parallel)(\n\u001b[0;32m    189\u001b[0m               X_train\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_t, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduplicate_K, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_all)[i][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_y[j], :], \n\u001b[0;32m    190\u001b[0m               y_train\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduplicate_K, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_y[j], :]\n\u001b[0;32m    191\u001b[0m               ) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_steps) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_uniques\n\u001b[0;32m    192\u001b[0m             )\n",
      "File \u001b[1;32mc:\\Users\\Tawfique\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Tawfique\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tawfique\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ForestDiffusion import ForestDiffusionModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Step 1: Load your dataset (assuming X is the feature matrix and y is the target variable)\n",
    "# Replace this with your data loading method\n",
    "file_path = 'diabetes.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Inspect the data and check for class imbalance\n",
    "# Assuming the last column is the label, and the rest are features\n",
    "X = data.iloc[:, :-1].values  # Features\n",
    "y = data.iloc[:, -1].values  # Labels (binary classification)\n",
    "\n",
    "# Check and print the original class distribution\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "class_dist_before = dict(zip(unique, counts))\n",
    "print(f\"Class distribution before augmentation: {class_dist_before}\")\n",
    "\n",
    "# Step 3: Plot the original imbalanced data (first two features for visualization)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', label='Original Data', s=1)\n",
    "plt.title('Original Imbalanced Data')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()\n",
    "# Separate the minority class\n",
    "X_minority = X[y == 1]\n",
    "\n",
    "# Step 2: Feature selection based on strongest correlation with the target\n",
    "# Using SelectKBest to select top features correlated with target\n",
    "selector = SelectKBest(score_func=f_classif, k=5)  # Adjust k based on the number of features to select\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Get selected feature indices and names\n",
    "selected_features = selector.get_support(indices=True)\n",
    "\n",
    "# Step 3: Calculate the correlation matrix for the selected features of the minority class\n",
    "X_selected_minority = X_minority[:, selected_features]\n",
    "correlation_matrix = pd.DataFrame(X_selected_minority).corr()\n",
    "print(\"Correlation Matrix of Selected Features:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Function to make the correlation matrix positive definite if necessary\n",
    "def make_positive_definite(matrix, epsilon=1e-5):\n",
    "    \"\"\"\n",
    "    Adjusts the matrix to be positive definite by adding epsilon to the diagonal elements.\n",
    "    \n",
    "    Args:\n",
    "        matrix (numpy.ndarray): The correlation matrix.\n",
    "        epsilon (float): Small value to add to the diagonal to ensure positive definiteness.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Positive definite matrix.\n",
    "    \"\"\"\n",
    "    # Check if the matrix is positive definite\n",
    "    eigenvalues = np.linalg.eigvalsh(matrix)\n",
    "    if np.all(eigenvalues > 0):\n",
    "        return matrix\n",
    "    \n",
    "    # Add epsilon to the diagonal if not positive definite\n",
    "    print(\"Adjusting matrix to be positive definite.\")\n",
    "    adjusted_matrix = matrix + np.eye(matrix.shape[0]) * epsilon\n",
    "    \n",
    "    # Re-check to confirm positive definiteness\n",
    "    eigenvalues = np.linalg.eigvalsh(adjusted_matrix)\n",
    "    assert np.all(eigenvalues > 0), \"Failed to make the matrix positive definite.\"\n",
    "    return adjusted_matrix\n",
    "\n",
    "# Step 4: Ensure the correlation matrix is positive definite\n",
    "positive_definite_corr_matrix = make_positive_definite(correlation_matrix.values)\n",
    "\n",
    "# Step 5: Upsample the minority class using ForestDiffusionModel\n",
    "int_columns = data.select_dtypes(include=['int']).columns\n",
    "int_indexes = []\n",
    "for col in int_columns:\n",
    "    col_index = data.columns.get_loc(col)\n",
    "    if col_index != 8:  # Skip column index 8\n",
    "        int_indexes.append(col_index)\n",
    "\n",
    "# Assuming you have defined ForestDiffusionModel previously\n",
    "forest_model = ForestDiffusionModel(X_minority, label_y=None, n_t=50, duplicate_K=100, \n",
    "                                    bin_indexes=[], cat_indexes=[], int_indexes=int_indexes, \n",
    "                                    diffusion_type='flow', n_jobs=-1)\n",
    "\n",
    "X_minority_fake = forest_model.generate(batch_size=len(X) // 50)\n",
    "\n",
    "# Function to adjust the correlations of the selected features in the generated data\n",
    "def adjust_selected_correlation(X, target_corr_matrix, selected_features):\n",
    "    \"\"\"\n",
    "    Adjusts the correlations of selected features in X to match the target correlation matrix.\n",
    "    \n",
    "    Args:\n",
    "        X (numpy.ndarray): The dataset whose selected features' correlations need adjusting.\n",
    "        target_corr_matrix (numpy.ndarray): The target correlation matrix for selected features.\n",
    "        selected_features (list): List of indices for the selected features.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Dataset with adjusted correlations for the selected features.\n",
    "    \"\"\"\n",
    "    # Extract only the selected features from X\n",
    "    X_selected = X[:, selected_features]\n",
    "    \n",
    "    # Calculate the Cholesky decomposition of the target correlation matrix\n",
    "    L = np.linalg.cholesky(target_corr_matrix)\n",
    "    \n",
    "    # Center the data for selected features\n",
    "    X_selected_centered = X_selected - np.mean(X_selected, axis=0)\n",
    "    \n",
    "    # Transform the selected features to match the target correlation structure\n",
    "    X_selected_transformed = np.dot(X_selected_centered, L.T) + np.mean(X_selected, axis=0)\n",
    "    \n",
    "    # Replace the selected features in the original dataset with the transformed features\n",
    "    X_adjusted = X.copy()\n",
    "    X_adjusted[:, selected_features] = X_selected_transformed\n",
    "    \n",
    "    return X_adjusted\n",
    "\n",
    "# Step 6: Adjust the synthetic data to match the correlation structure of selected features\n",
    "X_minority_fake_adjusted = adjust_selected_correlation(X_minority_fake, positive_definite_corr_matrix, selected_features)\n",
    "\n",
    "# Step 7: Add the generated samples to the main imbalanced dataset\n",
    "X_balanced = np.concatenate((X, X_minority_fake_adjusted), axis=0)\n",
    "y_balanced = np.concatenate((y, np.ones(X_minority_fake_adjusted.shape[0])), axis=0)\n",
    "\n",
    "# Check and print the class distribution after augmentation\n",
    "unique_bal, counts_bal = np.unique(y_balanced, return_counts=True)\n",
    "class_dist_after = dict(zip(unique_bal, counts_bal))\n",
    "print(f\"Class distribution after augmentation: {class_dist_after}\")\n",
    "\n",
    "# Step 8: Split the dataset into training and test sets (original and balanced)\n",
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_balanced, y_balanced, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 9: Train a simple classifier on both original and generated datasets\n",
    "clf_orig = RandomForestClassifier(random_state=42)\n",
    "clf_orig.fit(X_train_orig, y_train_orig)\n",
    "\n",
    "clf_bal = RandomForestClassifier(random_state=42)\n",
    "clf_bal.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Step 10: Predict and calculate recall and F1 scores\n",
    "y_pred_orig = clf_orig.predict(X_test_orig)\n",
    "y_pred_bal = clf_bal.predict(X_test_orig)\n",
    "\n",
    "recall_orig = recall_score(y_test_orig, y_pred_orig)\n",
    "recall_bal = recall_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "f1_orig = f1_score(y_test_orig, y_pred_orig)\n",
    "f1_bal = f1_score(y_test_orig, y_pred_bal)\n",
    "\n",
    "# Step 11: Print the performance metrics\n",
    "print(f\"Recall score (original data): {recall_orig:.4f}\")\n",
    "print(f\"Recall score (generated data): {recall_bal:.4f}\")\n",
    "print(f\"F1 score (original data): {f1_orig:.4f}\")\n",
    "print(f\"F1 score (generated data): {f1_bal:.4f}\")\n",
    "\n",
    "print(\"Classification Report (original data):\\n\", classification_report(y_test_orig, y_pred_orig))\n",
    "print(\"Classification Report (generated data):\\n\", classification_report(y_test_orig, y_pred_bal))\n",
    "\n",
    "# Step 12: Print the number of fake samples generated\n",
    "print(f\"Number of fake samples generated: {len(X_minority_fake_adjusted)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LlamaENVpip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
